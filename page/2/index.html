<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#33363b">
    <meta name="msapplication-TileColor" content="#33363b">
    
    
    
    <meta name="keywords" content="Life, ARIA, Hexo">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#33363b">
    
    
    <link rel="manifest" href="/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    
    
    <link rel="alternate" href="/atom.xml" title="dequn's blog" type="application/atom+xml" />
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/css/sidebar.css">
    
    
    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/css/atom-one-dark.css">
    <link rel="stylesheet" type="text/css" href="/css/lightgallery.min.css">
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/js/util.js"></script>
    <script defer type="text/javascript" src="/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-zoom.min.js"></script>
    
    <script defer src="/js/busuanzi.pure.mini.js"></script>
    
    
    
    <script defer type="text/javascript" src="/js/index.js"></script>
    
    <script defer type="text/javascript" src="/js/custom.js"></script>
    <title>dequn's blog - 这些文章没啥用</title>
  </head>
  <body itemscope itemtype="http://schema.org/WebPage" lang="en"  data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #33363b;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/">dequn's blog</a></h1>
        <h2 class="subtitle">这些文章没啥用</h2>
      </div>
      <div class="logo">
        <img src="/images/ARIA_logo.png" alt="logo">
      </div>
    </div>
    
<nav id="nav" class="nav">
  <a id="nav-toggle" class="nav-toggle"><i class="fas fa-bars"></i></a>
  <ul id="menu">
    
    <li><a href="/">Home</a></li>
    
    <li><a href="/archives/">Archives</a></li>
    
    <li><a href="/categories/">Categories</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
    <li><a href="/about/">About</a></li>
    
  </ul>
</nav>


  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container">
          <div class="content">
            

<section id="index" class="index">
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/12/27/jiu-zhe-teng-dao-zhe-er-ba/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/12/27/jiu-zhe-teng-dao-zhe-er-ba/" itemprop="url">就折腾到这儿吧</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-12-27T19:00:58+08:00">2016-12-27 19:00:58</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/个人日记/" itemprop="url" rel="index"><span itemprop="name">个人日记</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <p>上上周从百度搜索部Rank组面试回来之后，就有点不安，三面的面试官直接告诉我这面的表现不好，让她很担心。说这句话分明是让我很担心，核心部门还是很值得期待的。一周都没有音信，想必是挂掉了，不曾想今天接到HR电话联系offer事宜，终于可以把心放肚子里了。</p>
<p>今年四月份的时候面了一次腾讯实习，不意外地终止在一面。回来之后那个惶恐啊，突然间发现以自身的能力什么工作都找不到，但同时还欠着小论文没写，刚换了题目还没有看文献，一下子都不知道该做什么了。接下来的几个月也是最痛苦的，东一棒槌西一榔头，压根没有主心骨。</p>
<p>好在暑期的时候终于把小论文凑完了，赶紧刷算法，面试也都陆陆续续的开始了，准备了不到一个月，就进入秋招高峰期，也就没有再静心准备了。笔试一个接着一个，面试仍还是倒在一面。腾讯地图部门提前批感觉还不错，结果不行，微店一面感觉不好，挂掉…从来不知道二面是什么样子，更担心——妈的这得到什么时候才能找到工作。</p>
<p>面京东的时候比较顺利，虽然在一二面中已经知道岗位不是我想做的，但为了保底也要面下去，滑稽的是HR面挂了…真是见鬼了，短短5分钟的电面，我想犯错都难啊。后来华为也是，两面觉得非常顺利，不料仍然是failed，莫非真如师兄所说的：我犯了低级错误？但已然不记得了…</p>
<p>百度是第一个给offer的公司，也是唯一一个给了两次offer的。9月份校招面试机器学习，一面就挂了，面试官觉得coding还不错，推荐我去面开发测试，并给了一点职业规划的建议（真是好人啊，哈哈），后来顺利通过开发测试的三轮面试，所以说多数人当天都是三轮面试，我却面了四轮，也是够有趣的。之后觉得岗位不太合适就拒绝掉了，需要说明的是我一直是以岗位为目标的，对公司没有什么要求，所以后面一个小公司给了数据挖掘的岗位觉得还不错就签了，搜狗面试要我进去做web开发，犹豫了一下之后就以“目前还没有在web开发上有较清晰的职业规划”婉拒了，也就不意外的无果而终了。</p>
<p>现在想来真是作，为什么非得一根筋的非得去面数据挖掘\机器学习，压根没有任何相关的项目经验怎么去面！在签了小公司的数据挖掘岗位后进入观望阶段，赶紧的补补课，事实上囫囵吐枣半懂不懂地学习了一段时间后就也没再坚持。直到看到百度搜索部门的补招信息，并意外的有面试机会，真心不容易。一二面还不错，三面面试官在说了我表现不好之后还补充一句：其实你的简历在机器筛选的时候就没能通过，后来看你项目经历涉及的方面比较多，所以才又给提出来看看你的综合能力…</p>
<p>简历平平，因为能力、经历实在是太一般，也难怪很多公司始终没给我面试的机会。大师兄没少给加油打气，导致我自己都快相信他说的了（肯定没问题！），思考后才明白:鼓励不是你已经做到了，而是需要做到的，我们太容易认为那些鼓励的话都已是事实了。</p>
<p>这已经是我能折腾到的最好结果了，纯粹是撞运气的结果，论真实力怎么也不可能胜任的。虽然我也是个百度黑，很多人也骂它，但能“委身”于这样的现实也很满足了。接下来就是有个明确的规划和计划，总不能跳离的时候还是平平吧？</p>
<p>感谢给我内推的师兄、师姐和一些个招聘平台，感谢老板给我开放、自由的时间和空间，感谢周围的小伙伴儿，最后感谢一下面试官吧。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/面试/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>面试</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/11/20/zeppelin-installation-and-settings/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/11/20/zeppelin-installation-and-settings/" itemprop="url">Zeppelin 安装配置的一些问题</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-11-20T14:15:30+08:00">2016-11-20 14:15:30</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Zeppelin/" itemprop="url" rel="index"><span itemprop="name">Zeppelin</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <h1 id="1-版本问题"><a href="#1-版本问题" class="headerlink" title="1.版本问题"></a>1.版本问题</h1><p>Zeppelin 从0.6.1版本开始，默认是基于 Spark 2.x 和 Scala 2.11版本进行编译的，亲测 Zeppelin 0.6.2与 Spark 1.6.x 版本是不兼容的，导致 Saprk Interpreters 不能正确运行，如果需要安装在老版本上的，需要自己从源码编译，可以指定 Spark、Hadoop等版本参数，可以参考 <a href="http://zeppelin.apache.org/docs/snapshot/install/build.html" target="_blank" rel="noopener">http://zeppelin.apache.org/docs/snapshot/install/build.html</a> ，如果是0.6.0版本，可与 Spark 1.6.x 之前的兼容运行。</p>
<h1 id="2-Phoenix-thin-连接问题"><a href="#2-Phoenix-thin-连接问题" class="headerlink" title="2.Phoenix-thin 连接问题"></a>2.Phoenix-thin 连接问题</h1><p><strong><em>2017年1月3号更新</em></strong>：</p>
<p>Phoenix for Spark 2.x Integration的补丁已经出来了，可以直接加载为DataFrame而不用通过JDBC的方式连接数据库了，会获得更高的效率。Pheonix for Spark 2.x 版本的问题可以参见<a href="https://issues.apache.org/jira/browse/PHOENIX-3333" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/PHOENIX-3333</a>，如何使用可以参见文章<a href="http://dequn.github.io/2016/11/08/phoenix-spark-setting/">Spark 连接 Phoenix 配置</a>。</p>
<hr>
<p>Zeppelin 从0.6.0版本开始支持 Phoenix 连接，<a href="http://www.phoenix.apache.org" target="_blank" rel="noopener">Phoenix</a>默认是在jdbc interpreter 中配置的，配置过程可以参考 <a href="https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix" target="_blank" rel="noopener">https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix</a> ，<strong>注意一定要在Dependencies中添加artifact 依赖，如果从 maven远程库下载太慢，可以直接填写本地<code>phoenix-&lt;version&gt;-thin-client.jar</code>文件路径，或者把 jar 文件复制到路径<code>ZEPPELIN_HOME/interpreter/jdbc</code>下。</strong></p>
<p>但是如果使用的是phoenix-thin 连接，会报错误</p>
<blockquote>
<p>No suitable driver found for <a href="http://localhost:8765" target="_blank" rel="noopener">http://localhost:8765</a></p>
</blockquote>
<p>原因可以参见 <a href="https://github.com/apache/zeppelin/pull/1442" target="_blank" rel="noopener">https://github.com/apache/zeppelin/pull/1442</a> ，提供我已经编译好的 <a href="http://obqjd695a.bkt.clouddn.com/zeppelin-jdbc-0.6.2.jar" target="_blank" rel="noopener">zeppelin-jdbc-0.6.2.jar</a>，替换掉 <strong><code>ZEPPELIN_HOME/interpreter/jdbc</code></strong> 下边对应的同名文件即可。</p>
<h3 id="文件下载-zeppelin-jdbc-0-6-2-jar"><a href="#文件下载-zeppelin-jdbc-0-6-2-jar" class="headerlink" title="文件下载:zeppelin-jdbc-0.6.2.jar"></a>文件下载:<a href="http://obqjd695a.bkt.clouddn.com/zeppelin-jdbc-0.6.2.jar" target="_blank" rel="noopener">zeppelin-jdbc-0.6.2.jar</a></h3><h1 id="3-zeppelin中用-scala-加载-jdbc-数据问题"><a href="#3-zeppelin中用-scala-加载-jdbc-数据问题" class="headerlink" title="3.zeppelin中用 scala 加载 jdbc 数据问题"></a>3.zeppelin中用 scala 加载 jdbc 数据问题</h1><p><strong><em>2017年1月3号更新</em></strong>：</p>
<p>好久没有使用，重新折腾了一下，发现<strong>org.apache.hadoop.tracing.SpanReceiverHost.get(xxx)报错</strong>是由于Zeppelin提供的Hadoop版本和Spark编译时指定的版本不一致引起，只需要使用$SPARK_HOME/jars/hadoop-annotations-2.7.3.jar、hadoop-auth-2.7.3.jar、hadoop-common-2.7.3.jar替换掉$ZEPPELIN_HOME/lib下的对应文件即可。具体可以参考<a href="http://blog.csdn.net/lsshlsw/article/details/53768756" target="_blank" rel="noopener">Zeppelin 0.6.2 使用spark2.x 的一些错误处理</a>。</p>
<hr>
<p>刚开始使用的是Spark 2.0.1，使用下面的代码用 jdbc 读取数据库中的数据，发现总是报错，第一个关于 xxx.hive.ql.xxx 的错误，在 interpreter 的配置中将<code>zeppelin.spark.useHiveContext</code>项设置为<code>false</code>即可，<del>如果后面org.apache.hadoop.tracing.SpanReceiverHost.get(xxx)还继续报错，可以 <strong>升级 Spark2.0.2试试</strong> ，我是无意在笔记本上使用 Spark2.0.2 发现的 。</del></p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">val <span class="keyword">jdbcDf </span>= spark.read</span><br><span class="line">.format(<span class="string">"jdbc"</span>)</span><br><span class="line">.option(<span class="string">"driver"</span>,<span class="string">"org.apache.phoenix.queryserver.client.Driver"</span>)</span><br><span class="line">.option(<span class="string">"url"</span>,<span class="string">"jdbc:phoenix:thin:url=http://localhost:8765;serialization=PROTOBUF"</span>)</span><br><span class="line">.option(<span class="string">"dbtable"</span>,<span class="string">"bigjoy.imos"</span>)</span><br><span class="line">.load()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">java.lang.RuntimeException: </span><span class="keyword">java.lang.RuntimeException: </span>Unable to <span class="keyword">instantiate </span><span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.client.HiveClientImpl.&lt;init&gt;(HiveClientImpl.scala:189)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">  <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.<span class="keyword">java:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.<span class="keyword">java:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState$$anon$1.&lt;init&gt;(HiveSessionState.scala:63)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:382)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:143)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:122)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">47</span> elided</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.RuntimeException: </span>Unable to <span class="keyword">instantiate </span><span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:86)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">69</span> more</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.reflect.InvocationTargetException: </span><span class="keyword">java.lang.NoSuchMethodError: </span><span class="keyword">org.apache.hadoop.tracing.SpanReceiverHost.get(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Lorg/apache/hadoop/tracing/SpanReceiverHost;</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">  <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.<span class="keyword">java:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.<span class="keyword">java:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">75</span> more</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.NoSuchMethodError: </span><span class="keyword">org.apache.hadoop.tracing.SpanReceiverHost.get(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Lorg/apache/hadoop/tracing/SpanReceiverHost;</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:634)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:619)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:354)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:104)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:140)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:146)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:159)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:177)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:600)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:620)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:199)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:74)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">80</span> more</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1]: <a href="http://zeppelin.apache.org/docs/snapshot/install/build.html" target="_blank" rel="noopener">Zeppelin 源码编译</a><br>[2]: <a href="https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix" target="_blank" rel="noopener">Zeppelin Phoenix Interpreter 配置</a><br>[3]: <a href="https://github.com/apache/zeppelin/pull/1442" target="_blank" rel="noopener">ZEPPELIN-1459: Zeppelin JDBC URL properties mangled</a><br>[4]: <a href="http://blog.csdn.net/lsshlsw/article/details/53768756" target="_blank" rel="noopener">Zeppelin 0.6.2 使用spark2.x 的一些错误处理</a></p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/Phoenix/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Phoenix</a>
        
        <a class="post-tag button" href="/tags/Spark/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Spark</a>
        
        <a class="post-tag button" href="/tags/Zeppelin/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>Zeppelin</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/11/19/debug-spark-in-intellij/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/11/19/debug-spark-in-intellij/" itemprop="url">Intellij IDEA 中调试 Spark Application</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-11-19T10:12:47+08:00">2016-11-19 10:12:47</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <p>Spark 新手一名，同样也是 Scala 菜鸟，由于对这两个都不是特别熟悉，所以希望能在 IDE中 coding 和 debug，但是调试 Spark 程序和往常接触过的不一样，并且有一些观念上的错误，总结一下。</p>
<h1 id="坑一：网络代理"><a href="#坑一：网络代理" class="headerlink" title="坑一：网络代理"></a>坑一：网络代理</h1><p>程序写好以后，可以直接 debug 的(只限于 spark.master= local[*]的场景)，由于使用了 ShadowSocks 全局代理翻墙，最初一直报错，Google 了好大会儿也没找到问原因，后来才猛的想起代理还开着，而 hosts 文件中恰恰没有 localhost 映射到127.0.0.1中，修改 hosts，解决。直接 debug 可以使用较小的数据进行测试，不是非得网上众多教程那样得 sbt package -&gt; spark-submit -&gt; Remote Debug 那样不方便。</p>
<h1 id="坑二：worksheet-运行？"><a href="#坑二：worksheet-运行？" class="headerlink" title="坑二：worksheet 运行？"></a>坑二：worksheet 运行？</h1><p>虽然 spark-shell也提供了交互式命令行，尝试代码非常方便，不用每次都 debug 启动 sprak，那样效率太低。然而保存代码就比较麻烦了，因此想着能不能使用 scala worksheet来运行，这样结果也即时可见，代码也不会丢失，尝试了一番，发现不行，有高手解释为：spark 的 REPL 解释器和 Scala 的不一样，因此里边是运行不了 spark 程序的。难道就没有其他办法了吗？有的，采用Scala Console 代替，在文件上右键点击，选择 Run Scala Console 即可，可以与把文件里的代码发送给 console 运行，虽然不如 worksheet 方便，但也好过 spark-sheel 或者每次都启动 debug了。</p>
<h1 id="坑三：debug-on-spark-cluster"><a href="#坑三：debug-on-spark-cluster" class="headerlink" title="坑三：debug on spark cluster"></a>坑三：debug on spark cluster</h1><p>这个和坑一有些类似，在老板的三台机器上搭建了一个小集群，并以 standlone cluster 方式运行，于是就直接在 cluster 上debug 吧，获取 sparkContext 的方式如代码所示<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val spark = SparkSession.builder().<span class="literal">master</span>(<span class="string">"spark://192.168.6.131:7077"</span>).appName(<span class="string">"bigjoy"</span>).getOrCreate()</span><br></pre></td></tr></table></figure></p>
<p>在控制台中的 Log 如下，不断地停掉和开启 Executor，心想也不至于吧，数据量没那么大呀！</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARN TaskSchedulerImpl: Initial job has<span class="built_in"> not </span>accepted any resources;<span class="built_in"> check </span>your cluster UI to ensure that workers are registered<span class="built_in"> and </span>have sufficient resources</span><br></pre></td></tr></table></figure>
<p>于是去检查 spark UI 的 log, 看到下面的错误</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java<span class="selector-class">.lang</span><span class="selector-class">.reflect</span><span class="selector-class">.UndeclaredThrowableException</span></span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.security</span><span class="selector-class">.UserGroupInformation</span><span class="selector-class">.doAs</span>(UserGroupInformation<span class="selector-class">.java</span>:<span class="number">1713</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span><span class="selector-class">.runAsSparkUser</span>(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">70</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$.run(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">174</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$.main(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">270</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span><span class="selector-class">.main</span>(CoarseGrainedExecutorBackend.scala)</span><br><span class="line">Caused by: org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkException</span>: Exception thrown <span class="keyword">in</span> awaitResult</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">77</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">75</span>)</span><br><span class="line">	at scala<span class="selector-class">.runtime</span><span class="selector-class">.AbstractPartialFunction</span><span class="selector-class">.apply</span>(AbstractPartialFunction<span class="selector-class">.scala</span>:<span class="number">36</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span><span class="variable">$addMessageIfTimeout</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">59</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span><span class="variable">$addMessageIfTimeout</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">59</span>)</span><br><span class="line">	at scala.PartialFunction<span class="variable">$OrElse</span>.apply(PartialFunction<span class="selector-class">.scala</span>:<span class="number">167</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span><span class="selector-class">.awaitResult</span>(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">83</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcEnv</span><span class="selector-class">.setupEndpointRefByURI</span>(RpcEnv<span class="selector-class">.scala</span>:<span class="number">88</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$<span class="variable">$anonfun</span><span class="variable">$run</span>$<span class="number">1</span>.apply<span class="variable">$mcV</span><span class="variable">$sp</span>(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">188</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span>$<span class="variable">$anon</span>$<span class="number">1</span>.run(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">71</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span>$<span class="variable">$anon</span>$<span class="number">1</span>.run(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">70</span>)</span><br><span class="line">	at java<span class="selector-class">.security</span><span class="selector-class">.AccessController</span><span class="selector-class">.doPrivileged</span>(Native Method)</span><br><span class="line">	at javax<span class="selector-class">.security</span><span class="selector-class">.auth</span><span class="selector-class">.Subject</span><span class="selector-class">.doAs</span>(Subject<span class="selector-class">.java</span>:<span class="number">422</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.security</span><span class="selector-class">.UserGroupInformation</span><span class="selector-class">.doAs</span>(UserGroupInformation<span class="selector-class">.java</span>:<span class="number">1698</span>)</span><br><span class="line">	... <span class="number">4</span> more</span><br><span class="line">Caused by: java<span class="selector-class">.io</span><span class="selector-class">.IOException</span>: Failed to connect to /<span class="number">192.168</span>.<span class="number">1.105</span>:<span class="number">51340</span></span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.network</span><span class="selector-class">.client</span><span class="selector-class">.TransportClientFactory</span><span class="selector-class">.createClient</span>(TransportClientFactory<span class="selector-class">.java</span>:<span class="number">228</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.network</span><span class="selector-class">.client</span><span class="selector-class">.TransportClientFactory</span><span class="selector-class">.createClient</span>(TransportClientFactory<span class="selector-class">.java</span>:<span class="number">179</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.NettyRpcEnv</span><span class="selector-class">.createClient</span>(NettyRpcEnv<span class="selector-class">.scala</span>:<span class="number">197</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.Outbox</span>$<span class="variable">$anon</span>$<span class="number">1</span>.call(Outbox<span class="selector-class">.scala</span>:<span class="number">191</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.Outbox</span>$<span class="variable">$anon</span>$<span class="number">1</span>.call(Outbox<span class="selector-class">.scala</span>:<span class="number">187</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.FutureTask</span><span class="selector-class">.run</span>(FutureTask<span class="selector-class">.java</span>:<span class="number">266</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="selector-class">.runWorker</span>(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">1142</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="variable">$Worker</span>.run(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">617</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">745</span>)</span><br><span class="line">Caused by: java<span class="selector-class">.net</span><span class="selector-class">.NoRouteToHostException</span>: No route to host: /<span class="number">192.168</span>.<span class="number">1.105</span>:<span class="number">51340</span></span><br><span class="line">	at sun<span class="selector-class">.nio</span><span class="selector-class">.ch</span><span class="selector-class">.SocketChannelImpl</span><span class="selector-class">.checkConnect</span>(Native Method)</span><br><span class="line">	at sun<span class="selector-class">.nio</span><span class="selector-class">.ch</span><span class="selector-class">.SocketChannelImpl</span><span class="selector-class">.finishConnect</span>(SocketChannelImpl<span class="selector-class">.java</span>:<span class="number">717</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.socket</span><span class="selector-class">.nio</span><span class="selector-class">.NioSocketChannel</span><span class="selector-class">.doFinishConnect</span>(NioSocketChannel<span class="selector-class">.java</span>:<span class="number">224</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.AbstractNioChannel</span><span class="variable">$AbstractNioUnsafe</span>.finishConnect(AbstractNioChannel<span class="selector-class">.java</span>:<span class="number">289</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKey</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">528</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKeysOptimized</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">468</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKeys</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">382</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.run</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">354</span>)</span><br><span class="line">	at io<span class="selector-class">.netty</span><span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.SingleThreadEventExecutor</span>$<span class="number">2</span>.run(SingleThreadEventExecutor<span class="selector-class">.java</span>:<span class="number">111</span>)</span><br><span class="line">	... <span class="number">1</span> more</span><br></pre></td></tr></table></figure>
<p>看到 IP:192.168.1.105 后猛然想起，个人使用的笔记本网络连接的是办公室的路由器，而办公室的路由器的 ip 才是和集群的机器 Ip 在同一局域网中，中间跨了级！办公室的路由器又没有设置端口映射，难怪找不到！改为使用单位的无线路由（和集群一个局域网）后就没有此错误了！或者也可以设置一下小路由器的端口映射！</p>
<h1 id="坑四：sbt-或-maven-中的依赖版本（包括小版本）一定要与集群一致"><a href="#坑四：sbt-或-maven-中的依赖版本（包括小版本）一定要与集群一致" class="headerlink" title="坑四：sbt 或 maven 中的依赖版本（包括小版本）一定要与集群一致"></a>坑四：sbt 或 maven 中的依赖版本（包括小版本）一定要与集群一致</h1><p>使用坑三中的 debug on cluster, 由于很早建立的 maven 工程，采用的是 org.apache.spark:spark-core_2.1:2.0.1依赖，后来搭建集群的时候2.0.2版本已经发布，所以采用了最新的，由于大版本一致，所以就没有在意，debug 的时候报以下错误：</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.InvalidClassException: org.apache.spark.executor.TaskMetrics; <span class="keyword">local</span> <span class="built_in">class</span> incompatible: stream classdesc serialVersionUID = <span class="number">-6966587383730940799</span>, <span class="keyword">local</span> <span class="built_in">class</span> serialVersionUID = <span class="number">-2231953621568687904</span></span><br></pre></td></tr></table></figure>
<p>此问题由小版本不一致导致，说来也正常，向下兼容很正常，但向上的，呵呵，所以保持一致吧！</p>
<h1 id="坑五：找不到类？"><a href="#坑五：找不到类？" class="headerlink" title="坑五：找不到类？"></a>坑五：找不到类？</h1><p>由于工程采用 maven 构建，我使用了 phoenix 的依赖，当 spark.master=local[*]的时候，调试没有任何问题，但是当把 spark.master 设置为 spark://spark-master:7077也就是采用集群的时候，会提示除 spark 自带的（core, sql,mllib, stream）库之外，其他的都提示找不到，解决方案除了 <strong> 1）参考网上的远程调试外</strong> ，现提供另一种方式，<strong> 2)类似于 Hadoop的调试方式</strong></p>
<h2 id="1-设置-artifact"><a href="#1-设置-artifact" class="headerlink" title="1.设置 artifact"></a>1.设置 artifact</h2><p>File -&gt; Project Structre, 在 Artifacts 里边新建一个 jar 包，选择主类，在 Output Layout 中可以删除 spark 相关的（因为集群中已经有了，其他集群中CASSPATH 包含的都可以省掉，减少 jar包体积），最后确认即可。</p>
<p><img src="http://obqjd695a.bkt.clouddn.com/new-artifact.png" alt=""><br><img src="http://obqjd695a.bkt.clouddn.com/artifact-setting.png" alt=""><br><img src="http://obqjd695a.bkt.clouddn.com/artifact-jar-setting.png" alt=""></p>
<h2 id="2-spark-添加-jar-依赖"><a href="#2-spark-添加-jar-依赖" class="headerlink" title="2.spark 添加 jar 依赖"></a>2.spark 添加 jar 依赖</h2><p>只需要个 sparkContext 添加 jar包即可，代码如下</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> val spark = SparkSession.builder().master(<span class="string">"spark://192.168.6.131:7077"</span>).appName(<span class="string">"bigjoy"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">//注意路径是编译后的路径</span></span><br><span class="line">    spark<span class="selector-class">.sparkContext</span><span class="selector-class">.addJar</span>(<span class="string">"/Users/dq/IdeaProjects/subject/out/artifacts/analysis_jar/analysis.jar"</span>)</span><br></pre></td></tr></table></figure>
<p>在debug 前，先 Build -&gt; Build Artifacts -&gt; xxx.jar，把代码中的路径替换为实际的路径，然后就可以像其他普通的代码一样调试了，不过发现运行的比较慢，因为没有与远程调试的进行对比，所以哪个更好一些就暂不能下结论了，不过这个免去了上传 jar 包、spark-submit、remote debug 等过程，简单一些。</p>
<p>就先总结这么多吧！</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/Spark/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Spark</a>
        
        <a class="post-tag button" href="/tags/Intellij-IDEA/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Intellij IDEA</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/11/08/phoenix-spark-setting/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/11/08/phoenix-spark-setting/" itemprop="url">Spark 连接 Phoenix 配置</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-11-08T14:06:40+08:00">2016-11-08 14:06:40</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Phoenix/" itemprop="url" rel="index"><span itemprop="name">Phoenix</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <p><strong><em>2017年1月3号更新：</em></strong></p>
<p>在Spark 2.x版本中更改了DataFrame的定义，而Phoenix4.9及以前(4.10后官方版本会修复）是在Spark1.x的环境下开发的，因此如果使用Spark2.x的环境，不能正常使用Phoenix Spark Interprter, 具体问题可以参考 <a href="https://issues.apache.org/jira/browse/PHOENIX-3333" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/PHOENIX-3333</a>，这里给出本人利用链接中的补丁编译后的phoenix，其他参考1.x版本中的配置方式即可。</p>
<p><a href="http://obqjd695a.bkt.clouddn.com/phoenix-4.9.0-HBase-1.2-server.jar" target="_blank" rel="noopener">phoenix-4.9.0-HBase-1.2-server.jar</a></p>
<p><a href="http://obqjd695a.bkt.clouddn.com/phoenix-4.9.0-HBase-1.2-client.jar" target="_blank" rel="noopener">phoenix-4.9.0-HBase-1.2-client.jar</a></p>
<hr>
<p>Phoenix 官方文档给出了如何配置Spark 连接的说明，但是由于版本更新比较快，教程已经有些过时了。</p>
<p>环境配置：</p>
<blockquote>
<p>Spark 1.5.2<br>Phoenix 4.8.0<br>HBase 1.1.2</p>
</blockquote>
<p>如果在 HBase上配置过 Phoenix ，服务端就不需要做任何改动了。</p>
<p>在<strong> Phoenix 4.8</strong> 版本中，已经没有官方示例中的<code>phoenix-&lt;version&gt;-client-spark.jar</code>的文件了，所有的客户端需要的 jar 只有一个<strong> <code>phoenix-&lt;version&gt;-client.jar</code></strong> ！</p>
<p>连接在 Spark 中连接Phoenix 也有两种方式：</p>
<h2 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h2><p>spark-shell 启动时添加 phoenix jar.</p>
<p>启动spark-shell 是添加参数–jars 即可<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --jars /usr/local/phoenix/phoenix<span class="number">-4.8</span><span class="number">.0</span>-HBase<span class="number">-1.1</span>-client.jar</span><br><span class="line"># ....</span><br><span class="line"># ....</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.spark._</span><br><span class="line"></span><br><span class="line"># 这一句不报错的话就说明搞定了</span><br></pre></td></tr></table></figure></p>
<h2 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h2><p>配置 spark-defaults.conf</p>
<p>如果不想每次启动都添加 –jars 参数，可以配置$SPARK_HOME/conf 下边的spark-defaults.conf文件，添加下面两个配置项，注意 jar 文件路径与名称的正确性。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.executor</span><span class="selector-class">.extraClassPath</span>      /usr/local/phoenix/phoenix-<span class="number">4.8</span>.<span class="number">0</span>-HBase-<span class="number">1.1</span>-client.jar</span><br><span class="line">spark<span class="selector-class">.driver</span><span class="selector-class">.extraClassPath</span>      /usr/local/phoenix/phoenix-<span class="number">4.8</span>.<span class="number">0</span>-HBase-<span class="number">1.1</span>-client.jar</span><br></pre></td></tr></table></figure></p>
<p>这样再启动spark-shell，就可以直接导入需要的包了，注意 SparkContext sc 和 SQLContext sqlContext 都已经是设置好了的，可以直接用。其他可以参考官方给出的示例。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/Phoenix/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Phoenix</a>
        
        <a class="post-tag button" href="/tags/spark/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>spark</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/11/02/pyenv-install-with-warnings/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/11/02/pyenv-install-with-warnings/" itemprop="url">pyenv安装多版本 Python 过程中提示警告</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-11-02T15:21:35+08:00">2016-11-02 15:21:35</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <p>在使用 pyenv 安装多版本 Python 时，有时候会遇到警告<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">WARNING:</span> The Python bz2 extension was not compiled. Missing the bzip2 <span class="class"><span class="keyword">lib</span>?</span></span><br><span class="line"><span class="symbol">WARNING:</span> The Python readline extension was not compiled. Missing the GNU readline <span class="class"><span class="keyword">lib</span>?</span></span><br><span class="line"><span class="symbol">WARNING:</span> The Python sqlite3 extension was not compiled. Missing the SQLite3 <span class="class"><span class="keyword">lib</span>?</span></span><br></pre></td></tr></table></figure></p>
<p>只需要根据提示安装就行了（CentOS7环境下):<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum <span class="keyword">install </span>readline readline-devel readline-static -y</span><br><span class="line">yum <span class="keyword">install </span>openssl openssl-devel openssl-static -y</span><br><span class="line">yum <span class="keyword">install </span>sqlite-devel -y</span><br><span class="line">yum <span class="keyword">install </span><span class="keyword">bzip2-devel </span><span class="keyword">bzip2-libs </span>-y</span><br></pre></td></tr></table></figure></p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/pyenv/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>pyenv</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/10/28/macvim-auto-im/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/10/28/macvim-auto-im/" itemprop="url">MacVim自动切换中英文输入法</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-10-28T19:58:50+08:00">2016-10-28 19:58:50</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Others/" itemprop="url" rel="index"><span itemprop="name">Others</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      <p>中文用户的使用 VIM 最痛苦的就是来回切换输入法了，还好，在 OS 系统下使用 MacVim 可以设置在命令模式下禁用输入法，这样有了自动切换的效果，设置如下：</p>
<p><strong>第一步</strong>.在.vimrc 中设置<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">set</span> noimd</span><br><span class="line"><span class="builtin-name">set</span> <span class="attribute">imi</span>=2</span><br><span class="line"><span class="builtin-name">set</span> <span class="attribute">ims</span>=2</span><br></pre></td></tr></table></figure></p>
<p><strong>第二步</strong>.在 MacVim 的 Preferences 中的 Advanced 标签中，<strong>取消勾选 Draw marked text line</strong>。</p>
<p>这样就可以达到一个自动切换的效果（只是在命令行模式下给禁用掉了而已），这个要比设置 vimim 好用多了，vimim 延迟太大，使用非常不方便。</p>
<p>参考：<br>[1].<a href="https://www.v2ex.com/t/45772" target="_blank" rel="noopener">https://www.v2ex.com/t/45772</a></p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/VIM/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>VIM</a>
        
        <a class="post-tag button" href="/tags/MacVim/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>MacVim</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/10/27/mapreduce-output-to-hbase-at-mapper-phase-without-reducer/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/10/27/mapreduce-output-to-hbase-at-mapper-phase-without-reducer/" itemprop="url">MapReduce 在 Map 阶段写数据库，没有 Reducer</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-10-27T15:58:41+08:00">2016-10-27 15:58:41</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/HBase/" itemprop="url" rel="index"><span itemprop="name">HBase</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      不设置 Reducer 的任务会有一个默认的 Reducer, 如果必要，明确设置job.setNumReduceTasks(0);
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/Hadoop/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Hadoop</a>
        
        <a class="post-tag button" href="/tags/MapReduce/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>MapReduce</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/10/07/phoenix-mapreduce-example/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/10/07/phoenix-mapreduce-example/" itemprop="url">用 Phoenix 跑 MapReduce 任务-官方例子</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-10-07T15:50:10+08:00">2016-10-07 15:50:10</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Phoenix/" itemprop="url" rel="index"><span itemprop="name">Phoenix</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      在 Phoenix 上跑 MapReduce 任务，重点在如何编译、打包 jar、运行。
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/Phoenix/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Phoenix</a>
        
        <a class="post-tag button" href="/tags/MapReduce/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>MapReduce</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/09/02/Phoenix-Secondary-Index-Exploration-Local-Index/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/09/02/Phoenix-Secondary-Index-Exploration-Local-Index/" itemprop="url">Phoenix Secondary Index初探之Local Index</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-09-02T20:54:37+08:00">2016-09-02 20:54:37</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Phoenix/" itemprop="url" rel="index"><span itemprop="name">Phoenix</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      Phoenix 二级索引中 Local Index 是通过在索引表中关联原始表的 Rowkey 来实现的。
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/HBase/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>HBase</a>
        
        <a class="post-tag button" href="/tags/Secondary-Index/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Secondary Index</a>
        
        <a class="post-tag button" href="/tags/Phoenix/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>Phoenix</a>
        
        <a class="post-tag button" href="/tags/Local-Index/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Local Index</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="index-post card" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://dequn.github.io/2016/08/29/Phoenix-Secondary-Index-Exploration-Global-Index/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
        <meta itemprop="name" content="dequn">
        <meta itemprop="description" content="这些文章没啥用">
        <meta itemprop="image" content="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="dequn's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2016/08/29/Phoenix-Secondary-Index-Exploration-Global-Index/" itemprop="url">Phoenix Secondary Index初探之Global Index</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2016-08-29T21:44:48+08:00">2016-08-29 21:44:48</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Phoenix/" itemprop="url" rel="index"><span itemprop="name">Phoenix</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-body" itemprop="articleBody">
      
      初步对 Phoenix 二级索引中的 Global Index 认识一下,它是通过完全新建的一个数据表来作为索引的，因此构建索引是必须包含要查询的字段，约束字段是构成索引表行健的必要条件，其他查询列必须包含在 INCLUDE 里边！
      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/tags/HBase/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>HBase</a>
        
        <a class="post-tag button" href="/tags/Secondary-Index/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Secondary Index</a>
        
        <a class="post-tag button" href="/tags/Phoenix/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>Phoenix</a>
        
        <a class="post-tag button" href="/tags/Global-Index/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Global Index</a>
        
      </div>
      
    </footer>
  </article>
  
  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-angle-right"></i></a>
  </nav>
  
  
</section>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" style="background: url(/images/sidebar_background.png);">
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTL1rxWN2-S8kC34oi2QhbeQdm1hRAhzQTEpm5AFhnG3tJ-ccTI" alt="dequn">
  
  <h1 class="author-name">dequn</h1>
  <h2 class="author-description"> 这些文章没啥用</h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">Archives</div>
      <div><a href="/archives/">39</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">Categories</div>
      <div><a href="/categories/">11</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">Tags</div>
      <div><a href="/tags/">49</a></div>
    </div>
    
  </div>
  
  <div class="rss">
    <a class="rss-link button sidebar-item" href="/atom.xml"><i class="fas fa-rss"></i>RSS</a>
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    
    
<hr>
<div class="social-link sidebar-item">
  <div><i class="far fa-address-card"></i>Social Links</p></div>
  <ul>
    
    <li><i class="fas fa-envelope"></i><a href="mailto:dqzhangchn@gmail.com" target="_blank">E-Mail</a></li>
    
    <li><i class="fab fa-github"></i><a href="https://github.com/dequn" target="_blank">GitHub</a></li>
    
  </ul>
</div>


    
    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #33363b;">
  <div class="container">
    <div class="back-to-top">
      <a id="back-to-top"><i class="fas fa-angle-double-up"></i></a>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">dequn</span><span class="year"><i class="far fa-copyright"></i>2018</span>
        </div>
        
        
<div class="busuanzi">
  <span id="busuanzi_container_site_pv"><i class="fas fa-eye"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv"></span></span>
</div>


        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          托管于<i class="fab fa-github-alt"></i><a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
          
        </div>
        <div class="powered-by">
          Proudly Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> | Theme is <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
