<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dequn&#39;s blog</title>
  
  <subtitle>这些文章没啥用</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dequn.github.io/"/>
  <updated>2018-06-20T11:32:21.000Z</updated>
  <id>http://dequn.github.io/</id>
  
  <author>
    <name>dequn</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于Django &amp; Channels &amp; WebSocket &amp; Twisted的物联网远程控制</title>
    <link href="http://dequn.github.io/2018/06/19/django-channels-websocket-iot-remote-control/"/>
    <id>http://dequn.github.io/2018/06/19/django-channels-websocket-iot-remote-control/</id>
    <published>2018-06-19T15:34:46.000Z</published>
    <updated>2018-06-20T11:32:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>公司业务需要开发IOT从硬件到软件的全部工作，由于一开始来的硬件工程师选择了基于TCP直接进行终端与控制中心交互，自己设计报文内容与格式，所以远程控制也需要自己实现。还是自己太年轻，放着好好的现成的MQTT协议不用，自己瞎折腾。</p><p>硬件终端与服务器的通讯模块采用的是普通的2G卡，这样才能与自己的服务器直接通信（电信的物联网卡只能连接华为云，移动的物联网卡只能连接Oneconnect云平台，然后再对接自己的业务系统）。为了节省终端电池电量，终端5分钟唤醒一次连接服务器上报数据，也就是在这个时候，需要服务器查询控制任务队列，下发给下位机。所以，这里有下面几个工作需要完成：</p><ul><li>前端用户界面操作，发送任务给后端服务器（React + Django)，随后等待得到控制结果状态</li><li>后端创建任务（写Redis)</li><li>下位机每5分钟连接一次上位机，上位机（Twisted）查询任务队列（Redis），将对应的任务下发给下位机，下位机获取控制报执行相应操作后，返回控制结果给上位机</li><li>上位机返回控制结果给web后端(Redis 发布)，后端监听服务（订阅 Redis）返回给前端（WebSocket）</li><li>前端拿到结果，UI反馈给用户</li></ul><p>其中，不是必须通过Web后端才可以给硬件的上位机发送任务（这里是Twisted进程），比如本身就可以使用<a href="https://github.com/crossbario/autobahn-python" target="_blank" rel="noopener">autobahn-python</a>直接搭建一个WAMP，其运行在Twisted上，就可以省去一步交互了。由于在这个项目中涉及到权限验证、开关抽象（一个下位机有多个开关）等工作，所以还把这层放在Django中，反而省去很多开发。</p><p>另外需要说明一下为什么web前后端之间用WebSocket，因为这里的任务相当于<strong>异步任务</strong>，前后端都不知道下位机执行任务的准确时间，除了前端轮询的解决方案，最好的就是建立一个双工长连接，这样当web后端一旦知道任务结果，就可以主动发送给前端，因此WebSocket是最合适的方案。当然，Django本身不支持长连接，幸得有大牛开发了<a href="https://github.com/django/channels" target="_blank" rel="noopener">channels</a>，使得我们可以基于Django开发WebSocet服务，并且还支持异步！</p><p>以上的过程画成图是这样的!</p><p><img src="http://obqjd695a.bkt.clouddn.com/blog/iot-remote-control-sequence.png" alt="iot-remote-control-sequence"></p><p>补充：</p><ul><li>任务队列是写Redis</li><li>注意任务队列消费过后，要删除（即此次任务已执行，不论结果成功与否）</li><li>Django Channels需要建立一个后台监听服务（<a href="https://channels.readthedocs.io/en/latest/topics/channel_layers.html#using-outside-of-consumers" target="_blank" rel="noopener">Channel layers using outside of consumer</a>），第一时间通知给web前端</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;公司业务需要开发IOT从硬件到软件的全部工作，由于一开始来的硬件工程师选择了基于TCP直接进行终端与控制中心交互，自己设计报文内容与格式，所以远程控制也需要自己实现。还是自己太年轻，放着好好的现成的MQTT协议不用，自己瞎折腾。&lt;/p&gt;
&lt;p&gt;硬件终端与服务器的通讯模块采用
      
    
    </summary>
    
    
      <category term="Django" scheme="http://dequn.github.io/tags/Django/"/>
    
      <category term="Channels" scheme="http://dequn.github.io/tags/Channels/"/>
    
      <category term="WebSocket" scheme="http://dequn.github.io/tags/WebSocket/"/>
    
      <category term="IOT" scheme="http://dequn.github.io/tags/IOT/"/>
    
  </entry>
  
  <entry>
    <title>django-allauth配置微信登陆</title>
    <link href="http://dequn.github.io/2018/06/12/django-allauth-weixin-login/"/>
    <id>http://dequn.github.io/2018/06/12/django-allauth-weixin-login/</id>
    <published>2018-06-12T13:16:50.000Z</published>
    <updated>2018-06-13T14:09:19.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://django-allauth.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">django-allauth</a>很方便地继承了第三方登陆的功能，但其说明文档并不是很详细，配置一个demo都捉摸了好长时间，这里就以微信订阅号登陆为例，详细地说明一下配置过程，以供其他新上手地小伙伴参考。</p><h1 id="获取微信订阅号开发appid"><a href="#获取微信订阅号开发appid" class="headerlink" title="获取微信订阅号开发appid"></a>获取微信订阅号开发appid</h1><p>微信公众平台提供了一个测试号方便开发，登陆<a href="https://mp.weixin.qq.com/debug/cgi-bin/sandboxinfo?action=showinfo&amp;t=sandbox/index" target="_blank" rel="noopener">https://mp.weixin.qq.com/debug/cgi-bin/sandboxinfo?action=showinfo&amp;t=sandbox/index</a>即可获得一个appID和appsecret，这里但URL和Token都先可以留空，找到下边的<strong>网页授权获取用户基本信息</strong>，点击右侧的修改，测试号可以填写ip地址，这里为填写的是本地开发时候的本机ip:port, <strong>注意：这个地址是要会出现在回掉地址redirect_url中的，不一致将不能正确授权</strong>。【参考：<a href="https://www.cnblogs.com/0201zcr/p/5131602.html" target="_blank" rel="noopener">微信公众平台开发——微信授权登录（OAuth2.0）</a>】</p><p><img src="http://obqjd695a.bkt.clouddn.com/blog/django-allauth/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95%E5%8F%B7.png" alt="微信公众平台测试号"></p><p><img src="http://obqjd695a.bkt.clouddn.com/blog/django-allauth/%E6%89%BE%E5%88%B0%E7%BD%91%E9%A1%B5%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF.png" alt="找到网页获取用户基本信息"></p><p><img src="http://obqjd695a.bkt.clouddn.com/blog/django-allauth/%E5%A1%AB%E5%86%99%E5%9F%9F%E5%90%8D.png" alt="填写域名"></p><h1 id="安装配置django-allauth"><a href="#安装配置django-allauth" class="headerlink" title="安装配置django-allauth"></a>安装配置django-allauth</h1><p>django-allauth 的Doc已经把<a href="https://django-allauth.readthedocs.io/en/latest/installation.html" target="_blank" rel="noopener">安装过程</a>解释的很详细了，就不再重复，只说明一下比较容易出错的地方。</p><h2 id="site设置"><a href="#site设置" class="headerlink" title="site设置"></a>site设置</h2><p>django-allauth要求设置站点号，如果已经跟着安装过程进行到这一步的话，需要打开django的后台管理程序，会有一个设置好的site(example.com)。</p><h2 id="django-allauth-Social-applications设置"><a href="#django-allauth-Social-applications设置" class="headerlink" title="django-allauth Social applications设置"></a>django-allauth Social applications设置</h2><p>在后台管理找到Social applications，点击添加，把第一步在微信公众平台获取的appid和appsecret填进去，并选择刚刚设置的站点，保存，站点名称不一定需要与微信公众平台填写的一致，这里刚开始理解错了。【参考: <a href="http://www.marinamele.com/user-authentication-with-google-using-django-allauth" target="_blank" rel="noopener">Part VIII – User Authentication with a Google Account using Django Allauth</a>】</p><p><img src="http://obqjd695a.bkt.clouddn.com/blog/django-allauth/%E6%B7%BB%E5%8A%A0social%20application.png" alt="添加social application"></p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>下载一个<a href="https://mp.weixin.qq.com/wiki?action=doc&amp;id=mp1455784140" target="_blank" rel="noopener">微信web开发者工具</a>，输入微信登陆的地址<a href="http://10.0.0.8:8000/accounts/weixin/login/" target="_blank" rel="noopener">http://10.0.0.8:8000/accounts/weixin/login/</a> ，会提示授权、登陆（<code>/accounts/weixin/</code>路径是在django.settings文件中配置的），至此配置结束，在django后台中，可以看到Social accounts和Users两个表新增刚刚登陆的微信用户（allauth默认设置，参考<a href="https://django-allauth.readthedocs.io/en/latest/configuration.html" target="_blank" rel="noopener">Configuration</a>），测试完成！</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ul><li><p>微信公众平台中设置的域名，要和请求授权url中的回掉参数redirect_uri的域名是一模一样的。如果微信公众平台上的是线上域名，本地测试可以修改hosts文件。</p></li><li><p>如果使用allauth.weixin的登陆url，也就是<code>accounts/weixin/login</code>(跟着allauth的文档示例会配置成这样的），那么django的域名一定要与微信公众平台上设置的一致，否则默认的回掉地址是<code>django-domain/accounts/weixin/login/callback</code>，微信授权页面不能正常加载。</p></li><li><p>django-allauth的微信配置（我这里配置的是公众号内网页授权，不是pc端扫描二维码授权）。</p></li></ul><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SOCIALACCOUNT_PROVIDERS = &#123;</span><br><span class="line">    <span class="string">'weixin'</span>: &#123;</span><br><span class="line">        <span class="string">'AUTHORIZE_URL'</span>: <span class="string">'https://open.weixin.qq.com/connect/oauth2/authorize'</span>,</span><br><span class="line">        <span class="string">'SCOPE'</span>: [<span class="string">'snsapi_userinfo'</span>],</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>[1]. <a href="https://django-allauth.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">django-allauth</a><br>[2]. <a href="https://www.cnblogs.com/0201zcr/p/5131602.html" target="_blank" rel="noopener">微信公众平台开发——微信授权登录（OAuth2.0）</a><br>[3]. <a href="http://www.marinamele.com/user-authentication-with-google-using-django-allauth" target="_blank" rel="noopener">Part VIII – User Authentication with a Google Account using Django Allauth</a><br>[4]. <a href="https://django-allauth.readthedocs.io/en/latest/configuration.html" target="_blank" rel="noopener">Configuration</a><br>[5]. <a href="https://mp.weixin.qq.com/wiki?action=doc&amp;id=mp1455784140" target="_blank" rel="noopener">微信web开发者工具</a><br>[6]. <a href="https://open.weixin.qq.com/cgi-bin/showdocument?action=dir_list&amp;t=resource/res_list&amp;verify=1&amp;id=open1419316505&amp;token=&amp;lang=zh_CN" target="_blank" rel="noopener">网站应用微信登录开发指南</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://django-allauth.readthedocs.io/en/latest/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;django-allauth&lt;/a&gt;很方便地继承了第三方登陆的功能，但其说
      
    
    </summary>
    
    
      <category term="Django" scheme="http://dequn.github.io/tags/Django/"/>
    
      <category term="allauth" scheme="http://dequn.github.io/tags/allauth/"/>
    
      <category term="微信" scheme="http://dequn.github.io/tags/%E5%BE%AE%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>Django2结合Celery添加定时任务</title>
    <link href="http://dequn.github.io/2018/06/02/django-celery/"/>
    <id>http://dequn.github.io/2018/06/02/django-celery/</id>
    <published>2018-06-01T16:56:26.000Z</published>
    <updated>2018-06-01T18:02:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>项目需要对一些观测数值做监控预警，没有找到特别合适的专门的开源项目，因此决定采用Celery实现任务调度，当然，除了Cerlery，还有就是可以采用APScheduler实现，也有<a href="https://github.com/jarekwg/django-apscheduler" target="_blank" rel="noopener">django-apscheduler</a>的开源项目利用Django的ORM存储APScheduler的任务和调度信息，但是APScheduler并没有那么灵活，比如要想修改例行信息，是需要修改源代码并且重启Django进程才可以，也正是参考了这个<a href="https://stackoverflow.com/questions/11654353/how-to-setup-apscheduler-in-a-django-project/15929907" target="_blank" rel="noopener">Stackoverflow问题</a>，才决定选用Celery来调度任务。</p><p>关于Celery的定义，我想其项目网站主页的标题最为精确不过了——<strong>Distributed Task Queue</strong>，这里只简单的介绍一下Celery的工作模式，其他的使用细节可以参看网上的大量文章，不过建议以项目本身的文档为主，最为权威，尤其是在现在网络文章互相抄来抄去，质量极低！</p><p>Celery是一个分布式任务队列，那么就需要一个Broker也就是经纪人（我看好多人翻译成中间人，觉得好low啊）来存储和分发任务消息，Worker是实际执行任务的角色，Worker进程启动后，从经纪人那里读取并执行相应任务，任务是一早定义好的，可以手动调用，也可以用CelerBeat实现例行。如果了解生产者消费者模型的话，Worker对应消费者，CeleryBeat对应生产者。</p><p>也已经有开源项目<a href="https://github.com/celery/django-celery" target="_blank" rel="noopener">django-celery</a>，使得可以很方便的在Django中添加Celery任务，但是这个项目目前不支持Django 2及以上，原因是Celery调用的kombu库会抛出一个<code>missing 1 required positional argument: on_delete</code>的错误，而恰是在Django 2的时候，<code>on_delete</code>改成了必须字段，由于是Docker配置的开发环境，也懒得去修改镜像，因为Celery 本身就有对Django的支持，所以就自己动手，并不复杂。</p><p>具体的过程可以参考<a href="https://medium.com/@markgituma/using-django-2-with-celery-and-redis-21343284827c" target="_blank" rel="noopener">Using Django 2 with Celery and Redis</a> 和 官方文档<a href="http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html" target="_blank" rel="noopener">Using Celery with Django</a>，很简单就不上代码了，<strong>这里有一个很深的坑</strong>，celery.py中配置了任务自动发现<code>app.autodiscover_tasks()</code>，但<strong>在各个app中定义任务的模块名一定要是tasks，也就是示例代码中定义了任务的文件名一定要是tasks.py，而不能是其他的任何名称</strong>，因为自己尝试的时候手残敲错了，调试了很久才发现！</p><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> app1/</span></span><br><span class="line"><span class="ruby">    - tasks.py</span></span><br><span class="line"><span class="ruby">    - models.py</span></span><br><span class="line"><span class="ruby">- app2/</span></span><br><span class="line"><span class="ruby">    - tasks.py</span></span><br><span class="line"><span class="ruby">    - models.py</span></span><br></pre></td></tr></table></figure><p>另外还有一个需要注意的问题就是调用任务时<strong>任务的name</strong>该如何写，从哪一层模块开始也至关重要，<a href="http://docs.celeryproject.org/en/latest/userguide/tasks.html#task-naming-relative-imports" target="_blank" rel="noopener">task-naming-relative-imports</a>解释了why and how，这一点很多其他文章都没提及，也是容易出现的一个坑。具体放在Django中，以app1中任务为例，也就是在<code>INSTALLED_APPS</code>中添加的是app1，那么调用的时候要用到的任务名称就是<code>app1.tasks.task1</code>，也可以是嵌套的类如<code>app1.app2.tasks.task1</code>。</p><p>写了一个简单的<a href="https://github.com/dequn/django2-celery-demo" target="_blank" rel="noopener">django2-celery-demo</a>，以供参考。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1]. <a href="https://stackoverflow.com/questions/11654353/how-to-setup-apscheduler-in-a-django-project/15929907" target="_blank" rel="noopener">Stackoverflow: How to setup APScheduler in a Django project?</a><br>[2]. <a href="https://github.com/celery/django-celery" target="_blank" rel="noopener">django-celery</a><br>[3]. <a href="https://github.com/jarekwg/django-apscheduler" target="_blank" rel="noopener">django-apscheduler</a><br>[4]. <a href="https://medium.com/@markgituma/using-django-2-with-celery-and-redis-21343284827c" target="_blank" rel="noopener">Using Django 2 with Celery and Redis</a><br>[5]. <a href="http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html" target="_blank" rel="noopener">Using Celery with Django</a><br>[6]. <a href="http://docs.celeryproject.org/en/latest/userguide/tasks.html#task-naming-relative-imports" target="_blank" rel="noopener">task-naming-relative-imports</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;项目需要对一些观测数值做监控预警，没有找到特别合适的专门的开源项目，因此决定采用Celery实现任务调度，当然，除了Cerlery，还有就是可以采用APScheduler实现，也有&lt;a href=&quot;https://github.com/jarekwg/django-apsc
      
    
    </summary>
    
    
      <category term="Django" scheme="http://dequn.github.io/tags/Django/"/>
    
      <category term="Celery" scheme="http://dequn.github.io/tags/Celery/"/>
    
      <category term="APScheduler" scheme="http://dequn.github.io/tags/APScheduler/"/>
    
  </entry>
  
  <entry>
    <title>python3调用twisted web request的坑</title>
    <link href="http://dequn.github.io/2018/05/31/python3-twisted-web-client/"/>
    <id>http://dequn.github.io/2018/05/31/python3-twisted-web-client/</id>
    <published>2018-05-31T11:04:59.000Z</published>
    <updated>2018-06-01T00:47:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>硬件终端发送数据给服务器采用的是TCP直接传输，自己定义了二进制数据流格式，选来选去采用了Twisted开发TCP服务器。在数据外露的时候，采用Django开发了一个网站，因为在Django中已经定义了数据模型，不能也不想定义两次数据模型，所以Twisted接收到数据时，调用Django的REST接口保存数据到数据库，这就需要用到Twisted web client 发送数据。<a href="https://stackoverflow.com/questions/5051408/sharing-a-database-between-twisted-and-django" target="_blank" rel="noopener">该回答</a> 分析了在Twisted和Django中“共享数据库”的几种方法。</p><p>注：Twisted到最大优势在于异步非阻塞，而Django采用的是同步处理，如果直接引入Django的数据模型，这种同步处理放在Twisted的deferred里会让Twisted的优势丧失，所以采用了异步调用其他服务的方式。之所以现在采用Django进行网站开发，是因为现在是项目初期，能够快速开发落地是第一需求，但同时也兼顾到以后性能升级，所以保证各个模块的低耦合。</p><p>环境信息：</p><ul><li>Python 3.6.5</li><li>Twisted 18.4.0</li><li>Django 2.0.5</li></ul><p>关于Twisted web client<a href="https://twistedmatrix.com/documents/14.0.1/web/howto/client.html" target="_blank" rel="noopener">官网</a>给出了很详细的示例，但跟着实验下来的情况竟然是没有反应，服务器根本都没接到任何请求！</p><p>程序（参考官方示例）报的第一个错误是<code>TypeError: url must be bytes, not unicode</code>，没在意直接在url的字面量前加了一个<code>b</code>，其实这给后来的debug带来了极大的困难，因为一切都是按照示例写的，而根本看不到发送请求，没有版本只能再去翻看Twisted 的<a href="https://twistedmatrix.com/documents/14.0.1/api/twisted.web.iweb.IAgent.html#request" target="_blank" rel="noopener">API DOC</a>了，这才发现，原来在Python3中，request的绝大多数参数要求是<code>bytes</code>类型，而示例其实是Python2的代码，把所有字符串都转换成<code>bytes</code>，问题解决。</p><p>还有一点需要特别注意的是，request请求的url必须带上<code>http://</code>协议前缀，不然服务器端也是接收不到请求的！</p><p>最后，刚开始写Python3的代码，还真是有些不适应，一些细节需要特别注意。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1]. <a href="https://twistedmatrix.com/documents/14.0.1/api/twisted.web.iweb.IAgent.html#request" target="_blank" rel="noopener">https://twistedmatrix.com/documents/14.0.1/api/twisted.web.iweb.IAgent.html#request</a><br>[2]. <a href="https://stackoverflow.com/questions/5051408/sharing-a-database-between-twisted-and-django" target="_blank" rel="noopener">Sharing a database between Twisted and Django</a><br>[3]. <a href="https://twistedmatrix.com/documents/14.0.1/web/howto/client.html" target="_blank" rel="noopener">Using the Twisted Web Client</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;硬件终端发送数据给服务器采用的是TCP直接传输，自己定义了二进制数据流格式，选来选去采用了Twisted开发TCP服务器。在数据外露的时候，采用Django开发了一个网站，因为在Django中已经定义了数据模型，不能也不想定义两次数据模型，所以Twisted接收到数据时，调
      
    
    </summary>
    
    
      <category term="Django" scheme="http://dequn.github.io/tags/Django/"/>
    
      <category term="Python3" scheme="http://dequn.github.io/tags/Python3/"/>
    
      <category term="Twisted" scheme="http://dequn.github.io/tags/Twisted/"/>
    
      <category term="web" scheme="http://dequn.github.io/tags/web/"/>
    
      <category term="request" scheme="http://dequn.github.io/tags/request/"/>
    
  </entry>
  
  <entry>
    <title>Docker的OS image是做什么用的</title>
    <link href="http://dequn.github.io/2018/04/01/why-docker-has-OS-image/"/>
    <id>http://dequn.github.io/2018/04/01/why-docker-has-OS-image/</id>
    <published>2018-04-01T00:41:01.000Z</published>
    <updated>2018-04-01T13:49:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>这两天闲来无事，简单入门了一下Docker。主要参考的有阮一峰老师的两篇文章——<a href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html" target="_blank" rel="noopener">Docker 入门教程</a>、<a href="http://www.ruanyifeng.com/blog/2018/02/docker-wordpress-tutorial.html" target="_blank" rel="noopener">Docker 微服务教程</a>和 yeasy的开源项目<a href="https://yeasy.gitbooks.io/docker_practice/content/" target="_blank" rel="noopener">Docker — 从入门到实践</a>，照葫芦画瓢简单入门，不过离真正理解认清楚容器的特点、必要性，如何实践在持续交付和部署以及容器云等实际的运维应用还有很长的路要走。当我看到Docker 的OS image例如CentOS/Fedora、Busybox、Alphine等镜像的时候，不禁怀疑，既然我可以docker pull一个很简单命令就可以实现如Nginx, mysql等微服务的启动和部署，那为什么还会存在这些OS image, 这些OS image 的作用是什么？</p><p>在解决这个问题之前，首先需要明白几个和容器以及OS相关的定义，英文比较简单，直接从<a href="http://www.floydhilton.com/docker/2017/03/31/Docker-ContainerHost-vs-ContainerOS-Linux-Windows.html" target="_blank" rel="noopener">Understanding Docker “Container Host” vs. “Container OS” for Linux and Windows Containers</a>粘过来了，也强烈建议看看这篇文章，对于理解”OS”很有帮助。</p><blockquote><p><strong>Container Host</strong>: Also called the Host OS. The Host OS is the operating system on which the Docker client and Docker daemon run. In the case of Linux and non-Hyper-V containers, the Host OS shares its kernel with running Docker containers. For Hyper-V each container has its own Hyper-V kernel.<br> <strong>Container OS</strong>: Also called the Base OS. The base OS refers to an image that contains an operating system such as Ubuntu, CentOS, or windowsservercore. Typically, you would build your own image on top of a Base OS image so that you can take utilize parts of the OS. Note that windows containers require a Base OS, while Linux containers do not.<br> <strong>Operating System Kernel</strong>: The Kernel manages lower level functions such as memory management, file system, network and process scheduling.</p></blockquote><h2 id="菜鸟回答"><a href="#菜鸟回答" class="headerlink" title="菜鸟回答"></a>菜鸟回答</h2><p>基于以上信息，已经可以给出我这种菜鸟回答了：Docker的每一个镜像都必须有一个Base OS, 这个Base OS 可以是 Linux 的发行版，也可以是windows的，上边已经提到，这个Base OS 在Host OS 是Linux的时候可以“不必要”，其实，是一种特殊的Base OS 叫做<a href="https://hub.docker.com/r/library/scratch/" target="_blank" rel="noopener">scratch</a>，文章<a href="https://docs.docker.com/develop/develop-images/baseimages/" target="_blank" rel="noopener">Create a base image</a>给出了如何基于scratch创建一个Base Image（Base image 和 Base OS image 不是一样的概念!）。</p><p>我们所使用的常见的image，基本上都是以一个Host OS image为base的， 暨Dockerfile中都会有类似<code>FROM debian:stretch-slim</code>的基于OS image的语句。以nginx 为例，nginx既有基于debian也有基于alpine的镜像，tag分别是nginx:version和nginx:version-alpine，查看其Dockerfile可以看出，最大的不同点在于一个是<code>FROM debian:stretch-slim</code>和<code>FROM alpine:3.7</code>。下载镜像，可以看出其大小的区别，不得不说，基于alpine的和基于debian的镜像大小确实不是一个量级的。文章<a href="https://www.brianchristner.io/docker-image-base-os-size-comparison/" target="_blank" rel="noopener">Docker Base Image OS Size Comparison</a>对不同的Base OS image大小做了一个对比，感兴趣的可以看一看。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">nginx               <span class="number">1.13</span><span class="number">.10</span>-alpine      <span class="number">91</span>ce6206f9d8        <span class="number">10</span> days ago         <span class="number">18</span>MB</span><br><span class="line">nginx               <span class="number">1.13</span><span class="number">.10</span>             <span class="number">7</span>f70b30f2cc6        <span class="number">10</span> days ago         <span class="number">109</span>MB</span><br></pre></td></tr></table></figure><h2 id="再进一步"><a href="#再进一步" class="headerlink" title="再进一步"></a>再进一步</h2><p>文章<a href="https://blog.risingstack.com/operating-system-containers-vs-application-containers/" target="_blank" rel="noopener">Operating System Containers vs. Application Containers</a>讲述了虚拟机和容器的实现上的区别，可以很明白地看到，容器是直接基于Host OS kernel的，这也就是为什么在Mac和Windows上的Docker Client是基于Linux VM的<a href="https://docs.docker.com/develop/develop-images/baseimages/" target="_blank" rel="noopener">[5]</a>。在文章<a href="http://www.floydhilton.com/docker/2017/03/31/Docker-ContainerHost-vs-ContainerOS-Linux-Windows.html" target="_blank" rel="noopener">[4]</a>也可以看到，如果是Windows类型的容器，是必须建立在Winndows type的Base image上，或者是一个完整的“虚拟机容器”。</p><p><img src="http://obqjd695a.bkt.clouddn.com/os-virtualization.jpg" alt=""></p><p><a href="https://serverfault.com/questions/659557/os-docker-container-what-is-the-difference-with-a-vm-then" target="_blank" rel="noopener">Stackoverflow</a> 上有一个回答挺不错的，解释了为什么会有Base image，同样贴出原文，可以很明白的看到，Base image 提供的正式容器运行需要的<strong> root filesystem</strong>。</p><blockquote><p>Now you should wonder how is it possible to get a process runing inside a linux base image different from the linux distribution your host is running with. For an OS to run you basically need : </p><ul><li>A boot filesystem : contains the bootloader and the kernel that will reside in memory once loaded. We don’t care about this in the case of Docker containers because the kernel is shared with the host and is the common part between all linux distributions.</li><li>A root filesystem : contains the filesystem structure. It may be different from one linux distribution to another. It’s read-only until the boot sequence has finished.</li></ul></blockquote><p>如果从Docker的分层架构上来看<a href="https://blog.risingstack.com/operating-system-containers-vs-application-containers/" target="_blank" rel="noopener">[8]</a>，为什么需要Base image也会明朗许多。 在另一个 <a href="https://serverfault.com/questions/755607/why-do-we-use-a-os-base-image-with-docker-if-containers-have-no-guest-os" target="_blank" rel="noopener">Stackoverflow</a>上同样有一个不错的回答，这个回答中说的是<strong>userland</strong>，感兴趣的也可以看一下。</p><p><img src="http://obqjd695a.bkt.clouddn.com/docker-layers.png" alt=""></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html" target="_blank" rel="noopener">Docker 入门教程</a></li><li><a href="http://www.ruanyifeng.com/blog/2018/02/docker-wordpress-tutorial.html" target="_blank" rel="noopener">Docker 微服务教程</a></li><li><a href="https://yeasy.gitbooks.io/docker_practice/content/" target="_blank" rel="noopener">Docker — 从入门到实践</a></li><li><a href="http://www.floydhilton.com/docker/2017/03/31/Docker-ContainerHost-vs-ContainerOS-Linux-Windows.html" target="_blank" rel="noopener">Understanding Docker “Container Host” vs. “Container OS” for Linux and Windows Containers</a></li><li><a href="https://docs.docker.com/develop/develop-images/baseimages/" target="_blank" rel="noopener">Create a base image</a> </li><li><a href="https://www.brianchristner.io/docker-image-base-os-size-comparison/" target="_blank" rel="noopener">Docker Base Image OS Size Comparison</a></li><li><a href="https://blog.risingstack.com/operating-system-containers-vs-application-containers/" target="_blank" rel="noopener">Operating System Containers vs. Application Containers</a></li><li><a href="https://serverfault.com/questions/659557/os-docker-container-what-is-the-difference-with-a-vm-then" target="_blank" rel="noopener">OS docker container: what is the difference with a VM then?</a></li><li><a href="https://serverfault.com/questions/755607/why-do-we-use-a-os-base-image-with-docker-if-containers-have-no-guest-os" target="_blank" rel="noopener">Why do we use a OS Base Image with Docker if containers have no Guest OS?</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这两天闲来无事，简单入门了一下Docker。主要参考的有阮一峰老师的两篇文章——&lt;a href=&quot;http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopen
      
    
    </summary>
    
      <category term="Docker" scheme="http://dequn.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://dequn.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>理解python with语句</title>
    <link href="http://dequn.github.io/2017/12/02/%E7%90%86%E8%A7%A3python-with%E8%AF%AD%E5%8F%A5/"/>
    <id>http://dequn.github.io/2017/12/02/理解python-with语句/</id>
    <published>2017-12-02T05:50:08.000Z</published>
    <updated>2017-12-03T11:45:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>Python中的with语句可谓是相当的好用了，省去了<code>try...finally...</code>的复杂写法，<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html" target="_blank" rel="noopener">浅谈 Python 的 with 语句</a> 一文写的已经非常详细里，解决了使用过程中的两点疑问。文中的代码清单也主要摘自这篇文章。</p><p>清单1: with语句执行过程<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">context_manager = context_expression</span><br><span class="line"><span class="keyword">exit</span> = type(context_manager).__exit__  </span><br><span class="line">value = type(context_manager).__enter__(context_manager)</span><br><span class="line">exc = True   <span class="comment"># True 表示正常执行，即便有异常也忽略；False 表示重新抛出异常，需要对异常进行处理</span></span><br><span class="line">try:</span><br><span class="line">    try:</span><br><span class="line">        target = value  <span class="comment"># 如果使用了 as 子句</span></span><br><span class="line">        with-body     <span class="comment"># 执行 with-body</span></span><br><span class="line">    except:</span><br><span class="line">        <span class="comment"># 执行过程中有异常发生</span></span><br><span class="line">        exc = False</span><br><span class="line">        <span class="comment"># 如果 __exit__ 返回 True，则异常被忽略；如果返回 False，则重新抛出异常</span></span><br><span class="line">        <span class="comment"># 由外层代码对异常进行处理</span></span><br><span class="line">        <span class="keyword">if</span> not <span class="keyword">exit</span>(context_manager, *sys.exc_info()):</span><br><span class="line">            raise</span><br><span class="line">    finally:</span><br><span class="line">        <span class="comment"># 正常退出，或者通过 statement-body 中的 break/continue/return 语句退出</span></span><br><span class="line">        <span class="comment"># 或者忽略异常退出</span></span><br><span class="line">        <span class="keyword">if</span> exc:</span><br><span class="line">            <span class="keyword">exit</span>(context_manager, None, None, None) </span><br><span class="line">            <span class="comment"># 缺省返回 None，None 在布尔上下文中看做是 False</span></span><br></pre></td></tr></table></figure></p><p>从上边的逻辑可以看出，1.如果with语句块发生异常，那么执行except中的流程释放资源，并根据<code>exit()</code>函数返回值决定是否向上抛出异常；2.如果执行过程无异常，那么走finally中的逻辑释放资源。</p><h2 id="1-还用不用处理异常？"><a href="#1-还用不用处理异常？" class="headerlink" title="1. 还用不用处理异常？"></a>1. 还用不用处理异常？</h2><p>异常是必须处理的, with语句解决的只是保证了finally中的语句的执行，在with语句块内发生了异常而有没有处理，那么会直接执行with所代替的finally中的语句，并抛出异常给外层上下文，和正常情况下的异常处理流程是一样的。</p><h2 id="2-如果-exit-内部异常？"><a href="#2-如果-exit-内部异常？" class="headerlink" title="2. 如果__exit__内部异常？"></a>2. 如果<code>__exit__</code>内部异常？</h2><p>引用文章<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html" target="_blank" rel="noopener">浅谈 Python 的 with 语句</a> 中的解释:</p><blockquote><p>退出与上下文管理器相关的运行时上下文，返回一个布尔值表示是否对发生的异常进行处理。参数表示引起退出操作的异常，如果退出时没有发生异常，则3个参数都为None。如果发生异常，返回<br>True 表示不处理异常，否则会在退出该方法后重新抛出异常以由 with 语句之外的代码逻辑进行处理。如果该方法内部产生异常，则会取代由 statement-body 中语句产生的异常。要处理异常时，不要显示重新抛出异常，即不能重新抛出通过参数传递进来的异常，只需要将返回值设置为 False 就可以了。之后，上下文管理代码会检测是否 <strong>exit</strong>() 失败来处理异常</p></blockquote><p>通过例子来看一下：</p><ul><li>with语句块异常，但正确释放资源</li></ul><p>清单2: 自定义支持 with 语句的对象</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DummyResource</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, tag)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">self</span>.tag = tag</span><br><span class="line">    print <span class="string">'Resource [%s]'</span> % tag</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    print <span class="string">'[Enter %s]: Allocate resource.'</span> % <span class="keyword">self</span>.tag</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">self</span>   <span class="comment"># 可以返回不同的对象</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(<span class="keyword">self</span>, exc_type, exc_value, exc_tb)</span></span><span class="symbol">:</span></span><br><span class="line">    print <span class="string">'[Exit %s]: Free resource.'</span> % <span class="keyword">self</span>.tag</span><br><span class="line">    <span class="keyword">if</span> exc_tb is <span class="symbol">None:</span></span><br><span class="line">        print <span class="string">'[Exit %s]: Exited without exception.'</span> % <span class="keyword">self</span>.tag</span><br><span class="line">    <span class="symbol">else:</span></span><br><span class="line">        print <span class="string">'[Exit %s]: Exited with exception raised.'</span> % <span class="keyword">self</span>.tag</span><br><span class="line">    <span class="keyword">return</span> False   <span class="comment"># 可以省略，缺省的None也是被看做是False</span></span><br></pre></td></tr></table></figure><p>清单3: with语句块引起异常<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    <span class="keyword">with</span> DummyResource(<span class="symbol">'With</span>-<span class="keyword">Exception</span>'):</span><br><span class="line">         print '[<span class="keyword">with</span>-<span class="keyword">body</span>] Run <span class="keyword">with</span> <span class="keyword">exception</span>.'</span><br><span class="line">         <span class="keyword">raise</span> <span class="keyword">Exception</span>(<span class="symbol">'with</span>-block <span class="keyword">exception</span>')</span><br><span class="line">         print '[<span class="keyword">with</span>-<span class="keyword">body</span>] Run <span class="keyword">with</span> <span class="keyword">exception</span>. Failed to finish statement-<span class="keyword">body</span>!'</span><br><span class="line">except <span class="keyword">Exception</span> as e:</span><br><span class="line">    print e</span><br></pre></td></tr></table></figure></p><p>执行上边的代码，可以看到打印的信息，释放完资源后，异常抛出给with外层进行处理，如果外层没有<code>try</code>语句的话，在本例中会由系统打印调用栈并退出。<br>如果<code>__exit__</code>返回True，那么打印信息的最后一行<code>with-block exception</code>将不会被打印，因为with语句释放完资源后，把这个异常“压”下来了。<br>清单4: 正常释放资源，抛出原有异常<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Enter <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Allocate resource.</span><br><span class="line">[<span class="keyword">with</span>-<span class="keyword">body</span>] Run <span class="keyword">with</span> <span class="keyword">exception</span>.</span><br><span class="line">[<span class="keyword">Exit</span> <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Free resource.</span><br><span class="line">[<span class="keyword">Exit</span> <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Exited <span class="keyword">with</span> <span class="keyword">exception</span> raised.</span><br><span class="line"><span class="keyword">with</span>-block <span class="keyword">exception</span></span><br></pre></td></tr></table></figure></p><p>稍微对上边的代码修改一下，在<code>__exit__</code>函数中重新抛出一个异常，如清单5，重新执行清单3的调用，得到清单6的结果。<br>清单5：<code>__exit__</code>抛出异常<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_value, exc_tb)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'[Exit %s]: Free resource.'</span> % self.tag</span><br><span class="line">    <span class="keyword">if</span> exc_tb <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'[Exit %s]: Exited without exception.'</span> % self.tag</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'[Exit %s]: Exited with exception raised.'</span> % self.tag</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'new exception in __exit__'</span>)</span><br></pre></td></tr></table></figure></p><p>清单6: <code>__exit__</code>抛出新异常执行结果<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Resource [<span class="keyword">With</span>-<span class="keyword">Exception</span>]</span><br><span class="line">[Enter <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Allocate resource.</span><br><span class="line">[<span class="keyword">with</span>-<span class="keyword">body</span>] Run <span class="keyword">with</span> <span class="keyword">exception</span>.</span><br><span class="line">[<span class="keyword">Exit</span> <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Free resource.</span><br><span class="line">[<span class="keyword">Exit</span> <span class="keyword">With</span>-<span class="keyword">Exception</span>]: Exited <span class="keyword">with</span> <span class="keyword">exception</span> raised.</span><br><span class="line">__exit__ <span class="keyword">exception</span>.</span><br></pre></td></tr></table></figure></p><p>可以看出，如果<code>__exit__</code>重新抛出了一个异常，就会覆盖掉原有异常，如果资源正常释放，只需要返回False或者True来表示是否将with语句的异常抛给外层调用。</p><h2 id="3-其他使用"><a href="#3-其他使用" class="headerlink" title="3.其他使用"></a>3.其他使用</h2><p>使用contextmanager装饰器、nested函数、closing上下文管理器等语法可以参考<br>【<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html" target="_blank" rel="noopener">浅谈 Python 的 with 语句</a>】或者 【<a href="https://docs.python.org/release/2.6.6/library/contextlib.html" target="_blank" rel="noopener">contextlib — Utilities for with-statement contexts</a>】等文章，不再赘述。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html" target="_blank" rel="noopener">浅谈 Python 的 with 语句</a></li><li><a href="https://docs.python.org/release/2.6.6/library/contextlib.html" target="_blank" rel="noopener">contextlib — Utilities for with-statement contexts</a></li><li><a href="https://www.python.org/dev/peps/pep-0343/" target="_blank" rel="noopener">PEP 343 – The “with” Statement</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Python中的with语句可谓是相当的好用了，省去了&lt;code&gt;try...finally...&lt;/code&gt;的复杂写法，&lt;a href=&quot;https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/
      
    
    </summary>
    
    
      <category term="Python" scheme="http://dequn.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>关于目前工作的一点感想</title>
    <link href="http://dequn.github.io/2017/11/21/%E5%85%B3%E4%BA%8E%E7%9B%AE%E5%89%8D%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E6%83%B3/"/>
    <id>http://dequn.github.io/2017/11/21/关于目前工作的一点感想/</id>
    <published>2017-11-21T14:39:37.000Z</published>
    <updated>2017-12-02T05:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>从7月份入职以来，时时感觉到目前的工作跟我所期望的差别很大，但又不知道该如何取舍。</p><p>在面试的时候，经理问我是否愿意从事一些产品相关的工作，由于是岗位是机器学习，所以我想那么即使是产品相关，最起码也是要用到机器学习的，不论是数学层面、算法层面还是架构层面，这样是比较符合我的预期的，所以就签合同入职。可是入职这么久以来，发现当初没有对岗位做更多的了解，是很大的一个坑，这也是校招的同学普遍遇到的一个难点和痛点，除非是在公司以及组内部亲自实习过。</p><p>倒不是说这几个月来没有成长，而是在我所期望的技术以及能力层面上收效甚少。除了维护一些遗留下来的旧产品模块儿，就只剩下一个热词了。在入职以后，我也不得不承认自己与科班出身的同学差距比较大，同样的一个东西我可能需要吭哧好久，但是除了一些业务上的熟悉之外，没有得到更多我想要的成长了，而业务上的东西是带不走的，虽然熟悉公司内部的业务很重要。</p><p>原本也想着身处一个国内相对较好的技术环境内，再加上自己的学习，肯定能进步特别多。现在看来也是太天真了，团队技术是不错，每两周也会有分享，这些也都是有用的，但是收效也少。最为担心的事情是根本就没有自己的事件，每天醒来上班知道晚上回去，需求特别多，想在自己的方向上进行一些积累就显得欲求无门了。我层怀疑公司内部都是这么忙的，和一个从别的组转岗过来的同学，他说他们原来的组没有这边事情这么多，每天还是有很多自己学习、积累的时间，只有大搜才这么忙。</p><p>总说时间是海绵里的水，上高中时班主任也经常说我就是人太懒，当时还很不服气——自觉还不错。现在回想起来，我的自制力确实很弱，比如下班之后我是看不进去任何东西的（尤其是现在），在周六日的时候一个懒觉就占用了很多时间。也可能是我忘记了、放弃了曾经想要的，按现在这种状态下去也必定只能放弃，特别羡慕那些能够白天高效工作、晚上仍能坚持充电的牛人。还有就是白天的效率也不高，总觉得像是被KPI推动的走，没有主动性了。</p><p>如果这样久了，就没有跳出现有生活的动力和能力了；如果现在就跳出来，也没有那个能力，更是不能利用好目前这样一个平台。因此，还得必须自制自律，吃得苦中苦，方觉不知苦。</p><p>都说不忘初心，方得始终。初心是什么千万不能忘记，而为了初心，也定要付出更多才行！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从7月份入职以来，时时感觉到目前的工作跟我所期望的差别很大，但又不知道该如何取舍。&lt;/p&gt;
&lt;p&gt;在面试的时候，经理问我是否愿意从事一些产品相关的工作，由于是岗位是机器学习，所以我想那么即使是产品相关，最起码也是要用到机器学习的，不论是数学层面、算法层面还是架构层面，这样是
      
    
    </summary>
    
      <category term="个人日记" scheme="http://dequn.github.io/categories/%E4%B8%AA%E4%BA%BA%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="工作与初心" scheme="http://dequn.github.io/tags/%E5%B7%A5%E4%BD%9C%E4%B8%8E%E5%88%9D%E5%BF%83/"/>
    
  </entry>
  
  <entry>
    <title>Python字符串格式化</title>
    <link href="http://dequn.github.io/2017/10/05/python-str-formation/"/>
    <id>http://dequn.github.io/2017/10/05/python-str-formation/</id>
    <published>2017-10-05T09:24:10.000Z</published>
    <updated>2017-12-02T05:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>使用Python的时间也不短了，可是对字符串格式化的方式还是不怎么了解，尤其是对于自定义类型，如何实现友好的格式化输出？</p><p>printf-style的字符串格式化”%”号操作符的使用方法就不再赘述了，如果”%”后面不止一个参数，那么需要传入一个tuple，或者是一个dict。</p><p>由于”%”使用并不是那么方便，在非dict参数的情况下，tuple需要按照顺序组织，并且同一个参数不能够多次使用[<a href="https://mail.python.org/pipermail/python-3000/2006-April/000285.html" title="[Python-3000] String formating operations in python 3k" target="_blank" rel="noopener">1</a>]。于是就提出了使用模板进行字符串格式化的方法[<a href="https://www.python.org/dev/peps/pep-3101/#id9" title="PEP 3101 -- Advanced String Formatting" target="_blank" rel="noopener">2</a>]。这两种方法有在功能上有一定的重复，如何选择也全看个人喜好。</p><p>相对来说，模板格式化字符串功能更为强大和灵活，其语法可以参考[<a href="https://docs.python.org/3/library/string.html#formatstrings" title="string — Common string operations" target="_blank" rel="noopener">3</a>]，下面主要关注自定义类的格式化显示。</p><ul><li>在使用”%”操作符时，后面的转换字符代表的含义[<a href="https://docs.python.org/3/library/stdtypes.html#string-formatting-operations" target="_blank" rel="noopener">4</a>]:<blockquote><p>  ‘r’ String (converts any Python object using repr()).<br>  ‘s’    String (converts any Python object using str()).<br>  ‘a’    String (converts any Python object using ascii()).</p></blockquote></li></ul><p>对应的，我们可以定义自定义类的<code>__repr__()</code>、<code>__str__()</code> 来实现格式化输出（<code>ascii()</code>同<code>repr()</code>一样调用<code>__repr__()</code>，但会对non-ASCII字符进行转义，结果形如\x, \u, \U等[<a href="https://docs.python.org/3/library/functions.html#ascii" title="Built-in Functions" target="_blank" rel="noopener">5</a>]）。</p><ul><li>使用模板格式化时，我们除了可以使用内置的<code>!s</code>、<code>!r</code>、<code>!a</code>转换实现与上边相同的效果外，还可以通过定义类的<code>__format__</code>实现自定义格式化方法，这样就非常灵活了，线面通过例子来看一下。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line">class Test:</span><br><span class="line"></span><br><span class="line">    def __str__(self):</span><br><span class="line">        <span class="built_in">return</span> <span class="string">'in __str__()'</span></span><br><span class="line"></span><br><span class="line">    def __format__(self, format_spec):</span><br><span class="line">        <span class="keyword">if</span> format_spec == <span class="string">'own1'</span>:</span><br><span class="line">            <span class="built_in">return</span> <span class="string">'in __format__(), own1 method'</span></span><br><span class="line">        <span class="keyword">elif</span> format_spec == <span class="string">'s'</span>:</span><br><span class="line">            <span class="built_in">return</span> <span class="string">'in __format__(), s method'</span></span><br><span class="line">        <span class="keyword">elif</span> format_spec == <span class="string">'h'</span>:</span><br><span class="line">            <span class="built_in">return</span> <span class="string">'in __format__(), h method'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">return</span> <span class="string">'in __format__(), default method'</span></span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        <span class="built_in">return</span> <span class="string">'in __repr__()'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">test</span> = Test()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'str(test) shows '</span> + str(<span class="built_in">test</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">'repr(test) shows '</span> + repr(<span class="built_in">test</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'\n-----------% format ----------'</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'%%s shows %s'</span> % <span class="built_in">test</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'%%r shows %r'</span> % <span class="built_in">test</span></span><br><span class="line">    <span class="comment"># print '%%h shows %h' % test # will cause  ValueError: incomplete format</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'\n---------template format --------'</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;&#125;&#125; shows &#123;&#125;'</span>.format(<span class="built_in">test</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;!r&#125;&#125; shows &#123;!r&#125;'</span>.format(<span class="built_in">test</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;!s&#125;&#125; shows &#123;!s&#125;'</span>.format(<span class="built_in">test</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'\n---------template use __format__() --------'</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;:s&#125;&#125; shows &#123;:s&#125;'</span>.format(<span class="built_in">test</span>) <span class="comment"># use __format__ s conversion</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;:h&#125;&#125; shows &#123;:h&#125;'</span>.format(<span class="built_in">test</span>) <span class="comment"># use __format__ h conversion</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;:own1&#125;&#125; shows &#123;:own1&#125;'</span>.format(<span class="built_in">test</span>) <span class="comment"># use __format__ own1 conversion</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">'&#123;&#123;:&#125;&#125; shows &#123;:&#125;'</span>.format(<span class="built_in">test</span>) <span class="comment"># use __format__ default conversion</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">str(test) shows <span class="keyword">in</span> __str__()</span><br><span class="line">repr(test) shows <span class="keyword">in</span> __repr__()</span><br><span class="line"></span><br><span class="line">-----------% format ----------</span><br><span class="line">%s shows <span class="keyword">in</span> __str__()</span><br><span class="line">%r shows <span class="keyword">in</span> __repr__()</span><br><span class="line"></span><br><span class="line">---------template format --------</span><br><span class="line">&#123;&#125; shows <span class="keyword">in</span> __format__(),<span class="built_in"> default </span>method</span><br><span class="line">&#123;!r&#125; shows <span class="keyword">in</span> __repr__()</span><br><span class="line">&#123;!s&#125; shows <span class="keyword">in</span> __str__()</span><br><span class="line"></span><br><span class="line">---------template use __format__() --------</span><br><span class="line">&#123;:s&#125; shows <span class="keyword">in</span> __format__(), s method</span><br><span class="line">&#123;:h&#125; shows <span class="keyword">in</span> __format__(), h method</span><br><span class="line">&#123;:own1&#125; shows <span class="keyword">in</span> __format__(), own1 method</span><br><span class="line">&#123;:&#125; shows <span class="keyword">in</span> __format__(),<span class="built_in"> default </span>method</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>如果只是实现简单的格式化，那么”%”和模板都可以实现，自定义类通过定义<code>__str__()</code>和<code>__repr__()</code>来实现，但如果需要对一个类实现（多种）自定义转换的格式化，那么需要定义类的<code>__format__()</code>方法，并且只能通过使用模板来实现自定义转换的格式化。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://mail.python.org/pipermail/python-3000/2006-April/000285.html" title="[Python-3000] String formating operations in python 3k" target="_blank" rel="noopener">[Python-3000] String formating operations in python 3k</a></li><li><a href="https://www.python.org/dev/peps/pep-3101/#id9" title="PEP 3101 -- Advanced String Formatting" target="_blank" rel="noopener">PEP 3101 – Advanced String Formatting</a></li><li><a href="https://docs.python.org/3/library/string.html#formatstrings" title="string — Common string operations" target="_blank" rel="noopener">string — Common string operations</a></li><li><a href="https://docs.python.org/3/library/stdtypes.html#string-formatting-operations" target="_blank" rel="noopener">https://docs.python.org/3/library/stdtypes.html#string-formatting-operations</a></li><li><a href="https://docs.python.org/3/library/functions.html#ascii" title="Built-in Functions" target="_blank" rel="noopener">Built-in Functions</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用Python的时间也不短了，可是对字符串格式化的方式还是不怎么了解，尤其是对于自定义类型，如何实现友好的格式化输出？&lt;/p&gt;
&lt;p&gt;printf-style的字符串格式化”%”号操作符的使用方法就不再赘述了，如果”%”后面不止一个参数，那么需要传入一个tuple，或者是
      
    
    </summary>
    
      <category term="Python" scheme="http://dequn.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://dequn.github.io/tags/Python/"/>
    
      <category term="格式化" scheme="http://dequn.github.io/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Python模块的相对导入和绝对导入</title>
    <link href="http://dequn.github.io/2017/09/17/ways-of-python-import/"/>
    <id>http://dequn.github.io/2017/09/17/ways-of-python-import/</id>
    <published>2017-09-17T05:25:27.000Z</published>
    <updated>2017-09-17T07:49:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>刚开始用Python写代码，对于import的方式不是很理解，尤其是导入上层包的模块时，经常会使用<code>sys.path.append(&#39;..&#39;)</code>，然后再import，很不优雅，所以花些时间全部梳理一遍。</p><p>首先需要明白明白两个概念<strong>包</strong>和<strong>模块</strong>，很多人也都了解，贴出<a href="http://www.runoob.com/python/python-modules.html" title="http://www.runoob.com/python/python-modules.html" target="_blank" rel="noopener">runoob</a>（页面跟W3C好像，他们有什么关系吗？）上给出的两个定义。</p><ul><li><p>模块</p><blockquote><p>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。<br>模块让你能够有逻辑地组织你的 Python 代码段。<br>把相关的代码分配到一个模块里能让你的代码更好用，更易懂。<br>模块能定义函数，类和变量，模块里也能包含可执行的代码。</p></blockquote></li><li><p>包</p><blockquote><p>包是一个分层次的文件目录结构，它定义了一个由模块及子包，和子包下的子包等组成的 Python 的应用环境。<br>简单来说，包就是文件夹，但该文件夹下必须存在 <code>__init__.py</code> 文件, 该文件的内容可以为空。<code>__int__.py</code>用于标识当前文件夹是一个包。</p></blockquote></li></ul><p>从顶层模块（sys.path）或者当前的包中导入模块，使用<code>import module</code>或者<code>from module import xxx</code>的方式就不再赘述，不过有一种使用括号进行的多模块导入方式，如：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> from <span class="type">Tkinter</span> <span class="keyword">import</span> (<span class="type">Tk</span>, <span class="type">Frame</span>, <span class="type">Button</span>, <span class="type">Entry</span>, <span class="type">Canvas</span>, <span class="type">Text</span>,</span><br><span class="line">    <span class="type">LEFT</span>, <span class="type">DISABLED</span>, <span class="type">NORMAL</span>, <span class="type">RIDGE</span>, <span class="type">END</span>)</span><br></pre></td></tr></table></figure></p><p>这样可以避免使用反斜杠续行，稍微优雅一些，多行的字符串也可以使用一样的括号语法实现。记住，<code>from module import *</code>是绝对的不推荐的，会意外地“污染”命名空间。</p><p><strong>相对导入和绝对导入</strong>是这次讨论的重点，在项目中，肯定不意外地会建立不同层级和结构关系的包，那么在这些包之间，我们又应该如何导入要引用的模块？</p><h1 id="绝对导入"><a href="#绝对导入" class="headerlink" title="绝对导入"></a>绝对导入</h1><p>在Python 2.4之前，如果使用了<code>import foo</code>，如果当前包内也有一个模块foo，由于解释器是不知道你导入的是顶层模块还是当前包内的模块，根据模块寻找加载的顺序[]，当前包内的foo模块就会覆盖掉顶层的foo模块，而可能引起不必要的歧义。于是要求foo必须是在sys.path中能够寻到的模块或包，这就是绝对导入的定义。python-dev 社区选择将绝对导入作为默认导入的方式，一来是因为更常用，二是因为绝对导入可以提供相对导入的全部功能.</p><p>在Python 2.5 和 2.6中，绝对导入是可选的，需要在文件开头添加<code>from __future__ import absolute_import</code>来实现默认的绝对导入。</p><h1 id="相对导入"><a href="#相对导入" class="headerlink" title="相对导入"></a>相对导入</h1><p>相对导入是根据模块的<code>__name__</code>属性来决定模块的位置，然后计算相对路径，在同一个项目相邻层级的包和模块中最为常用，也最为方便。关于相对导入的语法实现模式，有一个很有趣也很广泛的讨论，看着那些先驱开发者的讨论，收获也是蛮多的，感兴趣的参考<a href="https://www.python.org/dev/peps/pep-0328/" title="PEP 328 -- Imports: Multi-Line and Absolute/Relative" target="_blank" rel="noopener">PEP 328 – Imports: Multi-Line and Absolute/Relative</a>。最后，Guido采用”.”前缀表示相对导入，和Unix系统中的目录表示含义一样，一个”.”表示当年层级，多一个就表示向上一层。下面是一些例子：<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .moduleY <span class="keyword">import</span> spam</span><br><span class="line"><span class="keyword">from</span> .moduleY <span class="keyword">import</span> spam <span class="keyword">as</span> ham</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> moduleY</span><br><span class="line"><span class="keyword">from</span> ..subpackage1 <span class="keyword">import</span> moduleY</span><br><span class="line"><span class="keyword">from</span> ..subpackage2.moduleZ <span class="keyword">import</span> eggs</span><br><span class="line"><span class="keyword">from</span> ..moduleA <span class="keyword">import</span> foo</span><br><span class="line"><span class="keyword">from</span> ...package <span class="keyword">import</span> bar</span><br><span class="line"><span class="keyword">from</span> ...sys <span class="keyword">import</span> path</span><br></pre></td></tr></table></figure></p><h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1><p>相对导入必须使用 <code>from .&lt;&gt; import xxx</code>(并且至少含有一个.符号)的模式，<code>import &lt;&gt;</code>总是绝对导入，当然，如果<code>from &lt;&gt; import</code>中没有句点，那么也是绝对导入。但是类似<code>import .foo</code>的方式是非合法语句，因为<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import XXX<span class="selector-class">.YYY</span><span class="selector-class">.ZZZ</span></span><br></pre></td></tr></table></figure></p><p>的<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XXX<span class="selector-class">.YYY</span><span class="selector-class">.ZZZ</span></span><br></pre></td></tr></table></figure></p><p>是可用的表达式，而<br><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> .moduleY</span><br></pre></td></tr></table></figure></p><p>的<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">.moduleY</span></span><br></pre></td></tr></table></figure></p><p>不是一个可用的表达式。</p><h1 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h1><p>使用相对导入还是绝对导入，可以完全凭个人喜好。但是为了代码的可阅读性，一般的共识是不超过两层的层级可以使用相对导入，试想一下，如果有超过3个的”.”，还能够正确快速地知道向上到了哪个层级吗?这个时候使用绝对导入会更加方便，代码也更好维护。不论哪一种导入方式，也都会有重构时的麻烦（如重命名一个模块），但是我想在IDE如此普遍使用的情况下，这个因素应该是最不值得考虑的了。加一个TODO吧，参阅一些优秀的开源框架源码，看看他们是如何组织的。</p><h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>使用了相对导入以后，如果直接以<code>python script_name.py</code>的方式运行脚本，Python解释器会报<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#python 2</span></span><br><span class="line"><span class="symbol">ValueError:</span> Attempted relative import <span class="keyword">in</span> non-package</span><br></pre></td></tr></table></figure></p><p>或者<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#python 3</span></span><br><span class="line">SystemError: Parent <span class="keyword">module</span> <span class="string">''</span> <span class="keyword">not</span> loaded, cannot perform relative <span class="keyword">import</span></span><br></pre></td></tr></table></figure></p><p>的错误，可以使用<code>python -m script_name.py</code>加上-m开关的方式运行，-m用于告诉解释器以脚本的方式运行模块，具体这样做的原因将在下一篇文章中分析。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="http://kuanghy.github.io/2016/07/21/python-import-relative-and-absolute" title="Python 相对导入与绝对导入" target="_blank" rel="noopener">Python 相对导入与绝对导入</a></li><li><a href="http://www.runoob.com/python/python-modules.html" title="http://www.runoob.com/python/python-modules.html" target="_blank" rel="noopener">http://www.runoob.com/python/python-modules.html</a></li><li><a href="https://www.python.org/dev/peps/pep-0328/" title="PEP 328 -- Imports: Multi-Line and Absolute/Relative" target="_blank" rel="noopener">PEP 328 – Imports: Multi-Line and Absolute/Relative</a></li><li><a href="http://codingpy.com/article/python-import-101/" title="Python导入模块的几种姿势" target="_blank" rel="noopener">Python导入模块的几种姿势</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;刚开始用Python写代码，对于import的方式不是很理解，尤其是导入上层包的模块时，经常会使用&lt;code&gt;sys.path.append(&amp;#39;..&amp;#39;)&lt;/code&gt;，然后再import，很不优雅，所以花些时间全部梳理一遍。&lt;/p&gt;
&lt;p&gt;首先需要明白明白两
      
    
    </summary>
    
      <category term="Python" scheme="http://dequn.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://dequn.github.io/tags/Python/"/>
    
      <category term="import" scheme="http://dequn.github.io/tags/import/"/>
    
  </entry>
  
  <entry>
    <title>终端高效切换编码</title>
    <link href="http://dequn.github.io/2017/09/05/switch-encoding-in-terminal/"/>
    <id>http://dequn.github.io/2017/09/05/switch-encoding-in-terminal/</id>
    <published>2017-09-05T12:51:21.000Z</published>
    <updated>2017-12-02T05:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>在以前的时候，终端编码通通设置的都是UTF-8，即使有一两台远程机，因为有自主权也都是UTF-8编码，包括数据库表格，也都是统一UTF-8编码，不得不说这样统一以后非常方便，几乎也没有考虑过编码不同带来的烦恼。</p><p>来到公司工作一段时间后才发现，自己的开发机还好说，设置成UTF-8就可以了，保持原有惯例。然而，需要经常登录别的机器看任务跑代码就会发现乱码了，好吧，手动把终端(iTerm2)调到GBK，结束以后再调回来；然后过了没两天，会发现其他机器的Mysql表格也是GBK的，好吧还得暂调GBK。最大的问题还不在于麻烦，我一个终端下连接了多台服务器和数据库，编码都不统一，这可怎么办？</p><p>在网上找到了两种方案，第一种是基于iTerm2的，可以参考<a href="http://blog.chenxiaosheng.com/posts/2013-10-29/mac_osx_iterm2_utf8_gbk_switch.html" target="_blank" rel="noopener">Mac OSX iTerm2 终端UTF-8和GBK编码自由切换</a>，虽然我是iTerm2的用户，但是觉得这种方法还是有些麻烦，如果我不用iTerm2还不能解决了？</p><p>当然还有其他利器，那就是luit.</p><p>参考IBM Knowledge Center上的介绍<a href="https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_61/com.ibm.aix.cmds3/luit.htm" target="_blank" rel="noopener">luit 命令</a></p><blockquote><p>luit 命令是一个过滤器，在任意应用程序和 UTF-8 终端仿真器之间运行。luit 命令将应用程序输出从语言环境的编码转换为 UTF-8，并将终端输入从 UTF-8 转换为语言环境的编码。</p><blockquote><p>注：<br>多语言应用程序必须设置为仅生成 UTF-8 代码。不得使用命令生成 UTF-8 之外的输出。</p></blockquote></blockquote><p>luit的安装也非常简单，参考 <a href="https://blog.jamespan.me/2015/06/12/luit-with-tmux" target="_blank" rel="noopener">Tmux、Luit 杂谈</a>过程如下。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget -c ftp:<span class="comment">//invisible-island.net/luit/luit.tar.gz</span></span><br><span class="line">tar -xzvf luit<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">cd luit-<span class="number">20141204</span>/</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>其使用可以man一下，或者参考<a href="https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_61/com.ibm.aix.cmds3/luit.htm" target="_blank" rel="noopener">luit 命令</a>，下面简单给出两个示例。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">luit </span>-encoding gbk ssh relay-mechine</span><br><span class="line"><span class="comment"># 这样登录远程机器用的就是GBK编码了</span></span><br></pre></td></tr></table></figure><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">luit </span>-encoding gbk mysql -u mysql_user -p </span><br><span class="line"><span class="comment">#这样连接数据库用的也是GBK编码</span></span><br></pre></td></tr></table></figure><p>最后不得不吐槽一下我司，是因为出于历史原因吗，固守GBK阵营？</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_61/com.ibm.aix.cmds3/luit.htm" target="_blank" rel="noopener">luit 命令</a></li><li><a href="https://blog.jamespan.me/2015/06/12/luit-with-tmux" target="_blank" rel="noopener">Tmux、Luit 杂谈</a></li><li><a href="http://blog.chenxiaosheng.com/posts/2013-10-29/mac_osx_iterm2_utf8_gbk_switch.html" target="_blank" rel="noopener">Mac OSX iTerm2 终端UTF-8和GBK编码自由切换</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在以前的时候，终端编码通通设置的都是UTF-8，即使有一两台远程机，因为有自主权也都是UTF-8编码，包括数据库表格，也都是统一UTF-8编码，不得不说这样统一以后非常方便，几乎也没有考虑过编码不同带来的烦恼。&lt;/p&gt;
&lt;p&gt;来到公司工作一段时间后才发现，自己的开发机还好说
      
    
    </summary>
    
      <category term="Linux" scheme="http://dequn.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://dequn.github.io/tags/Linux/"/>
    
      <category term="Encoding" scheme="http://dequn.github.io/tags/Encoding/"/>
    
  </entry>
  
  <entry>
    <title>Python中解析命令行参数</title>
    <link href="http://dequn.github.io/2017/09/02/parse-command-line-args-in-python/"/>
    <id>http://dequn.github.io/2017/09/02/parse-command-line-args-in-python/</id>
    <published>2017-09-02T13:47:03.000Z</published>
    <updated>2017-09-17T05:23:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>Python中常用的获取命令行参数的方法有三种，分别可适用于不同的场景。</p><h1 id="直接从sys-argv中获取"><a href="#直接从sys-argv中获取" class="headerlink" title="直接从sys.argv中获取"></a>直接从sys.argv中获取</h1><p>sys.agrv保存了命令行的参数列表，其中，<code>sys.argv[0]</code>保存的是脚本的名称，所以要获取自己传入的参数时，需要从第二个元素开始，参数的顺序与<code>sys.argv</code>中一致。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># m1.<span class="keyword">py</span></span><br><span class="line">import sys</span><br><span class="line"><span class="keyword">print</span> <span class="string">'The length of sys.argv is %d'</span> % <span class="built_in">len</span>(sys.<span class="built_in">argv</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'Argument list: '</span>,str(sys.<span class="built_in">argv</span>)</span><br></pre></td></tr></table></figure><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python m1.py <span class="keyword">first</span> <span class="keyword">second</span> <span class="keyword">third</span></span><br><span class="line">The <span class="built_in">length</span> <span class="keyword">of</span> sys.argv <span class="keyword">is</span> <span class="number">4</span></span><br><span class="line">Argument <span class="built_in">list</span>:  ['m1.py', '<span class="keyword">first</span>', '<span class="keyword">second</span>', '<span class="keyword">third</span>']</span><br></pre></td></tr></table></figure><p><strong>获这种方法适用于参数较少的时候，使用者按照固定顺序将所需参数传入即可，同时，取的参数都是str类型，需要用户自行转换为所需类型。</strong></p><h1 id="使用getopt-getopt获取参数"><a href="#使用getopt-getopt获取参数" class="headerlink" title="使用getopt.getopt获取参数"></a>使用getopt.getopt获取参数</h1><p>当参数比较多的时候我们可能需要明确指定参数名称，又或者我们可能需要一些可选参数，使用第一种方法就不是那么方便了，所以我们可以用getopt来解析参数，其调用方式如下所示。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">getopt</span><span class="selector-class">.getopt</span>(<span class="selector-tag">args</span>, <span class="selector-tag">options</span>, <span class="selector-attr">[long_options]</span>)</span><br></pre></td></tr></table></figure></p><ul><li>args是将被解析的参数列表</li><li>options是需要识别的参数名列表，当然不一定非得有参数，比如-h用来输出帮助信息，当有对应参数的时候，需要在标识符后边添加一个分号”:”。</li><li>long_options可选参数是长参数名列表，如–long-name，当有参数传入的时候，需要在右边添加等号”=”。</li></ul><p>函数返回一个二元组，第一个元素是（option,value)列表，第二个元素是未识别的参数列表。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#m2.<span class="keyword">py</span></span><br><span class="line">#codin<span class="variable">g:utf</span>-<span class="number">8</span></span><br><span class="line">import sys, getopt</span><br><span class="line"></span><br><span class="line">opts, left_args = getopt.getopt(sys.<span class="built_in">argv</span>[<span class="number">1</span>:], <span class="string">'i:h'</span>, [<span class="string">'in='</span>,<span class="string">'help'</span>]) #第一个参数是脚本名，不传入</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">opt</span>, val in <span class="keyword">opt</span><span class="variable">s:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">opt</span> == <span class="string">'-h'</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'不含参数Help Info'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">opt</span> == <span class="string">'--help'</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'不含参数Help Info2'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">opt</span> == <span class="string">'-i'</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'短参数-i: '</span>, val</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">opt</span> == <span class="string">'--in'</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'长参数--ifile: '</span>, val</span><br><span class="line"><span class="keyword">print</span> <span class="string">'未识别参数：'</span>, str(left_args)</span><br></pre></td></tr></table></figure><p>运行结果<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python m2<span class="selector-class">.py</span> -<span class="selector-tag">i</span> short_arg --<span class="keyword">in</span>=long_arg -h --help left_arg</span><br><span class="line">短参数-<span class="selector-tag">i</span>:  short_arg</span><br><span class="line">长参数--ifile:  long_arg</span><br><span class="line">不含参数Help Info</span><br><span class="line">不含参数Help Info2</span><br><span class="line">未识别参数： [<span class="string">'left_arg'</span>]</span><br></pre></td></tr></table></figure></p><p>这种方法已经能够应对大多数情况了，不过获取的val仍是str类型。</p><h1 id="使用argparse模块解析参数"><a href="#使用argparse模块解析参数" class="headerlink" title="使用argparse模块解析参数"></a>使用argparse模块解析参数</h1><p>argparse 模块最大的特点就是可以建立用户友好的命令行接口，可以实现指定需要传入的参数，自动解析sys.argv，自动生成帮助信息、错误信息等。如果要使用getopt来达到同样的效果，就需要写很多很多的代码啦。</p><p>argparse 通过ArgumentParser对象实现参数的解析，可以很友好地实现帮助信息、参数传入前缀、参数冲突等特性，其通过add_argument方法添加具体的参数——包括位置参数和可选参数等，同时可以指定这些参数的个数、转换类型、默认值、限定枚举值、是否必须以及别名等信息。argparse的使用会比上述两个复杂一些，但是其功能更强大、使用更友好一些。具体使用方法可以单独写一篇文章了，但是官方文档已经给出了很详细的示例了，所以这里就不在赘述，感兴趣的可以参阅<a href="https://docs.python.org/2.7/library/argparse.html" target="_blank" rel="noopener">argparse — Parser for command-line options, arguments and sub-commands</a>。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>上述三个方法从简单到复杂，功能从单一到丰富，开发人员可根据需要选择。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://www.tutorialspoint.com/python/python_command_line_arguments.htm" target="_blank" rel="noopener">Python Command Line Arguments</a></li><li><a href="https://docs.python.org/2.7/library/argparse.html" target="_blank" rel="noopener">argparse — Parser for command-line options, arguments and sub-commands</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Python中常用的获取命令行参数的方法有三种，分别可适用于不同的场景。&lt;/p&gt;
&lt;h1 id=&quot;直接从sys-argv中获取&quot;&gt;&lt;a href=&quot;#直接从sys-argv中获取&quot; class=&quot;headerlink&quot; title=&quot;直接从sys.argv中获取&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
      <category term="Python" scheme="http://dequn.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://dequn.github.io/tags/Python/"/>
    
      <category term="args" scheme="http://dequn.github.io/tags/args/"/>
    
  </entry>
  
  <entry>
    <title>字符集、字符编码以及Python中编码的那些事</title>
    <link href="http://dequn.github.io/2017/08/19/charset-encoding-and-in-python/"/>
    <id>http://dequn.github.io/2017/08/19/charset-encoding-and-in-python/</id>
    <published>2017-08-19T14:53:43.000Z</published>
    <updated>2017-08-24T15:02:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>总会遇到乱码的问题，也总是按照网上的教程一步一步操作，解决的过程就像碰运气，从来没有总结过，再次遇到的时候还是不知道是什么问题，所以，花一点时间，总结一下。</p><h1 id="字符集和字符编码"><a href="#字符集和字符编码" class="headerlink" title="字符集和字符编码"></a>字符集和字符编码</h1><p><strong>字符集</strong>是一个系统支持的抽象字符的集合。这个集合是有限集合，包括文字、标点和数字等，由于计算机内部全部都是数字存储，所以字符集本身也是一个符号与数字之间的映射关系，比如ASCII字符集中大写字母A的编号是65。存储或传输的时候计算机根据字符集将人能看懂的字符换算成计算机能看懂的数字，输出的时候再换算成人能看懂的字符。</p><p><strong>字符编码</strong>，计算机系统内部全部采用二进制，那么将数字转换成二进制的时候采用什么规则呢，比如采用几位，高位代表什么，低位代表什么等，这就是所谓的编码规则。</p><p><strong>乱码</strong>，计算机按照指定或默认的编码规则对bit位进行解码，由于与存储或接收时使用的编码规则不一致，就导致了翻译出来的字符不是原来的字符，造成所谓的乱码，即我们人类看不懂。</p><h1 id="常用的字符集和字符编码"><a href="#常用的字符集和字符编码" class="headerlink" title="常用的字符集和字符编码"></a>常用的字符集和字符编码</h1><p>常见的字符集有ASCII，能表示128个字符，扩展ASCII能表示256个字符，GBXXX字符集是我国专家设计的一套字符集，还有包括繁体字的汉字字符集BIG5，这些字符集同时规定了编码规则，所以他们<strong>同时也是字符编码</strong>，需要说明的是，他们都是兼容ASCII编码的。</p><h1 id="Unicode-和-UTF-8"><a href="#Unicode-和-UTF-8" class="headerlink" title="Unicode 和 UTF-8"></a>Unicode 和 UTF-8</h1><p>最容易搞混的是Unicode和UTF-8了，因为像上面那样每个语言或者地区都搞一套，在互联网中普及非常不便，于是就出现了<strong>Unicode字符集</strong>，目前已经超过了十万字符，可以包括多种文字，这个字符集规定了符号系统到数字的映射，但是并没有规定统一的编码规则。</p><p>UTF-8，UTF-16，UTF-32都是Unicode的编码规则，其中UTF-32同意采用4个字节表示字符，空间浪费较大，所以不常见，UTF-8是一种变长的编码方式，因为文本的重点不在于关注编码规则的细节，所以就不再赘述，具体实现可以参见其他作者的文章。</p><p><strong>所以，我们常见的GBXXX,ASCII,BIG5等本身即是指代字符集，也是字符编码，而Unicode只是字符集，UTF-8只是字符编码。</strong></p><h1 id="Python-中的编码"><a href="#Python-中的编码" class="headerlink" title="Python 中的编码"></a>Python 中的编码</h1><p>这里主要有三个问题：</p><ol><li>str和unicode类型有什么区别？</li><li>源文件开头的#coding:utf-8是做什么用的，跟源文件的编码有什么关系？</li><li>源文件的编码对程序有没有影响？</li><li>file = open(‘xxx’),file.read()是怎样对文件进行解码的？</li></ol><p>首先来看第一个问题，再Python2中，通过<code>s1=&#39;str字符串&#39;</code>得到的是str对象，而<code>s2=u&#39;unicode字符串&#39;</code>得到的是unicode对象，这两种都是<code>basestring</code>类型的子类，从官方文档<a href="https://docs.python.org/2/howto/unicode.html" target="_blank" rel="noopener">Unicode HOWTO</a>中的解释</p><blockquote><p>Python represents Unicode strings as either 16- or 32-bit integers, depending on how the Python interpreter was compiled.</p></blockquote><p>可以看出，unicode字符串可以看做直接存储的是该字符对应的Unicode数字码，在<a href="http://wklken.me/posts/2013/08/31/python-extra-coding-intro.html#str-he-unicode" target="_blank" rel="noopener">PYTHON-进阶-编码处理小结</a>一文中，还对比了用<code>len()</code>求两者长度的区别，其中，<code>len(&#39;中文&#39;)</code>得到的结果为6，而<code>len(u&#39;中文&#39;)</code>得到的结果才是实际意义上的2。在<a href="https://pythonhosted.org/kitchen/unicode-frustrations.html" target="_blank" rel="noopener">Overcoming frustration: Correctly using unicode in python2</a>中也解释了str类型和unicode类型的不同，str类型是实际上bytes序列，<code>len(str)</code>所得到的也是序列的长度，而不是实际意义上的字符串长度。</p><blockquote><p>In python, the unicode type stores an abstract sequence of code points. Each code point represents a grapheme. By contrast, byte str stores a sequence of bytes which can then be mapped to a sequence of code points. Each unicode encoding (UTF-8, UTF-7, UTF-16, UTF-32, etc) maps different sequences of bytes to the unicode code points.</p></blockquote><p>Python开发者通常会写<code>#coding: utf-8</code>或者类似的encoding hint在源文件的前两行（也只有在前两行才起作用，并且该编码必须兼容ASCII，UTF-16就不能正常工作）。 很多人明白的一点就是：<strong>如果源代码文件中出现了非ASCII字符集中的字符，我们需要写这样的注释</strong>。 但是对于像我这样的新手来说，常常会有一个问题，这句话的作用是什么，又和源文件本身的编码什么关系？</p><p>在Python2.1中，Unicode字符串只能采用”unicode-escape”的方式，比如需要定义”中文”两个字，须得<code>s = u&#39;\u4e2d\u6587&#39;</code>，而不能直接出现<code>s = u&#39;中文&#39;</code>这样的代码，这就对使用非拉丁字符的开发者非常不友好，所以就有了<a href="https://www.python.org/dev/peps/pep-0263/" target="_blank" rel="noopener">PEP263</a>，该网页中也解释了该lint的作用，即<strong>使用指定的编码将源代码中的字符串字面量转换成unicode，而这与源文件编码本身并没有直接关系</strong>。</p><blockquote><p>This PEP proposes to introduce a syntax to declare the encoding of a Python source file. The encoding information is then used by the Python parser to interpret the file using the given encoding. <strong>Most notably this enhances the interpretation of Unicode literals in the source code and makes it possible to write Unicode literals using e.g. UTF-8 directly in an Unicode aware editor</strong>.</p></blockquote><blockquote><p>…</p></blockquote><blockquote><p>In Python 2.1, Unicode literals can only be written using the Latin-1 based encoding “unicode-escape”. This makes the programming environment rather unfriendly to Python users who live and work in non-Latin-1 locales such as many of the Asian countries. <strong>Programmers can write their 8-bit strings using the favorite encoding, but are bound to the “unicode-escape” encoding for <em>Unicode literals</em> </strong>.</p></blockquote><p>有的读者可能看到了，刚才的引用中明明提到了</p><blockquote><p>The encoding information is then used by the Python parser to interpret the file using the given encoding.</p></blockquote><p>怎么能说与源文件的编码无关呢？</p><p>这里就需要了解Python解释器工作的流程了，在<a href="https://www.python.org/dev/peps/pep-0263/" target="_blank" rel="noopener">PEP263</a>中有说明：</p><blockquote><p>Python’s tokenizer/compiler combo will need to be updated to work as follows:<br>A. read the file<br>B. decode it into Unicode assuming a fixed per-file encoding<br>C. convert it into a UTF-8 byte string<br>D. tokenize the UTF-8 content<br>E. compile it, creating Unicode objects from the given Unicode data and creating string objects from the Unicode literal data by first reencoding the UTF-8 data into 8-bit string data using the given file encoding</p></blockquote><p>注意：步骤B中的encoding指的不是我们声明的<code>coding:encoding</code>，而是源文件保存在磁盘上的编码，我们用到的编码只在步骤E中使用到，下面的实验中也证明了这一点。</p><p>最后需要说明的是open(‘file’).read()得到的按字节读取的str类型，可以参考<a href="http://wklken.me/posts/2013/08/31/python-extra-coding-intro.html#str-he-unicode" target="_blank" rel="noopener">PYTHON-进阶-编码处理小结</a>。</p><p>现在有两个文件及其运行结果，因为我的终端环境为UTF-8，所以GB18030的str输出始终是乱码的。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#utf8.<span class="keyword">py</span></span><br><span class="line">#codin<span class="variable">g:utf</span>-<span class="number">8</span></span><br><span class="line"><span class="keyword">if</span>  __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'UTF-8源py中的str中文字符'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">u</span><span class="string">'UTF-8源py中的unicode中文字符'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./utf8text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline()</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./gb18030text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline().decode(<span class="string">'gb18030'</span>)</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line"></span><br><span class="line"># 运行:<span class="keyword">python</span> utf8.<span class="keyword">py</span></span><br><span class="line"></span><br><span class="line">UTF-<span class="number">8</span>源<span class="keyword">py</span>中的str中文字符</span><br><span class="line">UTF-<span class="number">8</span>源<span class="keyword">py</span>中的unicode中文字符</span><br><span class="line">UTF8文件中的编码</span><br><span class="line"></span><br><span class="line">GB18030�ļ��еı���</span><br></pre></td></tr></table></figure><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#gb18030.<span class="keyword">py</span></span><br><span class="line">#codin<span class="variable">g:</span> GB18030</span><br><span class="line"><span class="keyword">if</span>  __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'GB18030源py中的str中文'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">u</span><span class="string">'GB18030源py中的unicode中文'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./utf8text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline()</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./gb18030text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline()</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line"></span><br><span class="line">#python gb18030.<span class="keyword">py</span></span><br><span class="line">GB18030Դ<span class="keyword">py</span>�е�str����</span><br><span class="line">GB18030源<span class="keyword">py</span>中的unicode中文</span><br><span class="line">UTF8文件中的编码</span><br><span class="line"></span><br><span class="line">GB18030�ļ��еı���</span><br></pre></td></tr></table></figure><p>还有一个文件utf8gb18030.py，它的源文件编码为UTF-8，但是我在头部声明了<code>coding:utf-8</code>，来看一下这个文件的运行结果为什么：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#codin<span class="variable">g:</span> GB18030</span><br><span class="line"><span class="keyword">if</span>  __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'str:UTF-8源py中的中文字符,但是coding声明为GB18033'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">u</span><span class="string">'unicode:UTF-8源py中的中文字符,但是coding声明为GB18033'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./utf8text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline()</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">file</span> = <span class="keyword">open</span>(<span class="string">'./gb18030text'</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="keyword">file</span>.readline()</span><br><span class="line">    <span class="keyword">file</span>.<span class="keyword">close</span>()</span><br><span class="line"></span><br><span class="line"># <span class="keyword">python</span> utf8gb18030.<span class="keyword">py</span></span><br><span class="line">str:UTF-<span class="number">8</span>源<span class="keyword">py</span>中的中文字符,但是coding声明为GB18033</span><br><span class="line">unicode:UTF-<span class="number">8</span>婧恜<span class="keyword">y</span>涓殑涓枃瀛楃,浣嗘槸coding澹版槑涓篏B18033</span><br><span class="line">UTF8文件中的编码</span><br><span class="line"></span><br><span class="line">GB18030�ļ��еı���</span><br></pre></td></tr></table></figure><p>我们知道，unicode对象在print到时候会根据sys.out的默认编码进行encode()的，所以不应该出现乱码情况，但是在第三次试验中，本该乱码的str没有问题，不该出现乱码的unicode却乱码了，这说明在上述解释器运行的过程中，步骤B和步骤E使用的不是同一编码，否则运行结果中unicode是不会乱码的。虽然两者不必相等，但是我们也看到了，这会带来更大的困扰，更难定位问题所在，所以<strong>一定要保证源文件的编码与声明的<code>#coding:encoding</code>一致，否则很难跳出坑的</strong>。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>作为一个非纯Latin-1开发者，一定要在头部声明encoding hint。</li><li>为了避免不必要的麻烦，声明的encoding hint 一定要与源文件的编码一致。</li><li>在程序内部最好统一处理为unicode进行，在输出的时候在进行encode，如file.readline().decode(‘你的文件编码’)得到unicode，在写文件的时候可以指定unicode_str.encode(‘你需要的编码’)。</li><li>字面量字符串只是用u’xxx’得到unicode。</li><li>str可以decode得到unicode，unicode可以encode得到str，其他方向的编解码是不可行的！</li></ol><p>难免出错，还请不吝指教。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html" target="_blank" rel="noopener">字符编码笔记：ASCII，Unicode和UTF-8</a><br><a href="http://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html" target="_blank" rel="noopener">字符集和字符编码（Charset &amp; Encoding）</a><br><a href="cn.nytimes.com/culture/20150123/t23questions">关于Python脚本开头两行的：#!/usr/bin/python和# -<em>- coding: utf-8 -</em>-的作用 – 指定文件编码类型</a><br><a href="https://www.python.org/dev/peps/pep-0263/" target="_blank" rel="noopener">PEP 263 – Defining Python Source Code Encodings</a><br><a href="https://pythonhosted.org/kitchen/unicode-frustrations.html" target="_blank" rel="noopener">Overcoming frustration: Correctly using unicode in python2</a><br><a href="https://docs.python.org/2/howto/unicode.html" target="_blank" rel="noopener">Unicode HOWTO</a><br><a href="http://stormhouse.github.io/posts/2013/character-encoding-python/" target="_blank" rel="noopener">python中的字符编码</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;总会遇到乱码的问题，也总是按照网上的教程一步一步操作，解决的过程就像碰运气，从来没有总结过，再次遇到的时候还是不知道是什么问题，所以，花一点时间，总结一下。&lt;/p&gt;
&lt;h1 id=&quot;字符集和字符编码&quot;&gt;&lt;a href=&quot;#字符集和字符编码&quot; class=&quot;headerlin
      
    
    </summary>
    
      <category term="Python" scheme="http://dequn.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://dequn.github.io/tags/Python/"/>
    
      <category term="charset" scheme="http://dequn.github.io/tags/charset/"/>
    
      <category term="encode" scheme="http://dequn.github.io/tags/encode/"/>
    
  </entry>
  
  <entry>
    <title>d3-example-of-different-data-structures</title>
    <link href="http://dequn.github.io/2017/03/31/d3-example-of-different-data-structures/"/>
    <id>http://dequn.github.io/2017/03/31/d3-example-of-different-data-structures/</id>
    <published>2017-03-31T07:10:46.000Z</published>
    <updated>2017-08-24T15:03:54.000Z</updated>
    
    <content type="html"><![CDATA[<style>img{height:200px;}</style><p>A simple list of chart types and data structure.</p><h1 id="Single-property"><a href="#Single-property" class="headerlink" title="Single property"></a>Single property</h1><h2 id="Box-Plots"><a href="#Box-Plots" class="headerlink" title="Box Plots"></a>Box Plots</h2><ul><li>Description: Use for Statistics: the smallest value, lower quartile, median, upper quartile,<br>and largest value.</li><li>Example:None.</li></ul><h2 id="Bubble-Chart"><a href="#Bubble-Chart" class="headerlink" title="Bubble Chart"></a>Bubble Chart</h2><ul><li>Description: Statistics, the area of circel stands for the count of a value, proper<br>to large amount of values than <strong>Bar Chart</strong>.</li><li>Example: <img src="https://camo.githubusercontent.com/dbaf877e0e81e571ae42fa1f6e1115bf052f72ca/687474703a2f2f64336a732e6f72672f65782f627562626c652e706e67" alt=""></li></ul><h2 id="Bullet-Chart"><a href="#Bullet-Chart" class="headerlink" title="Bullet Chart"></a>Bullet Chart</h2><ul><li>Description: A variation on a bar chart, compare a quantitative measure anainst<br>qualiative ranges and related markders.</li><li>Example: <img src="https://camo.githubusercontent.com/490b4c309e5ecb769b3969bed04b3b49bf516065/687474703a2f2f64336a732e6f72672f65782f62756c6c65742e706e67" alt=""></li></ul><h2 id="Calendar-Chart"><a href="#Calendar-Chart" class="headerlink" title="Calendar Chart"></a>Calendar Chart</h2><ul><li>Description: Values are visualized as colored cells per day, Use for compartion<br>between moths/years while having a day value detail.</li><li>Example: <img src="https://camo.githubusercontent.com/bc2b1c93d21e80d23c99da8ebd59617e94581327/687474703a2f2f64336a732e6f72672f65782f63616c656e6461722e706e67" alt=""></li><li>Example: <img src="https://camo.githubusercontent.com/fb70dfff84f2b442e89a6799e13343eda2387dc1/68747470733a2f2f676973742e6769746875622e636f6d2f746a6465636b652f353535383038342f7261772f7468756d626e61696c322e706e67" alt=""></li></ul><h2 id="Circular-heat-chart"><a href="#Circular-heat-chart" class="headerlink" title="Circular heat chart"></a><a href="http://prcweb.co.uk/circularheatchart/" target="_blank" rel="noopener">Circular heat chart</a></h2><ul><li>Description: A head map with a circular layout.</li><li>Example: <img src="http://prcweb.co.uk/img/rainfall-1980-2012.jpg" alt=""></li><li>Example: <img src="https://github.com/nicgirault/circosJS/raw/master/doc/temperatures.png" alt=""></li></ul><h2 id="A-3d-exmaple-for-one-property"><a href="#A-3d-exmaple-for-one-property" class="headerlink" title="A 3d exmaple for one property"></a>A 3d exmaple for one property</h2><p><img src="https://camo.githubusercontent.com/be49e2d5950922a2b221d6578fb2fe0f84b69384/687474703a2f2f616e696d61746564646174612e636f2e756b2f696d672f64332d67616c6c6572792f756b74656d70657261747572656c696e6573332e6a7067" alt=""></p><h1 id="A-and-B"><a href="#A-and-B" class="headerlink" title="A and B"></a>A and B</h1><h2 id="Chord-Diagram"><a href="#Chord-Diagram" class="headerlink" title="Chord Diagram"></a>Chord Diagram</h2><ul><li>Description: Show directed relationships among a group of entities.</li><li>Example: <img src="https://camo.githubusercontent.com/cc8ad10f5975dff97a5d6801269f8203101b20b9/687474703a2f2f64336a732e6f72672f65782f63686f72642e706e67" alt="abc"></li></ul><h2 id="Force-Directed-Graph"><a href="#Force-Directed-Graph" class="headerlink" title="Force-Directed Graph"></a>Force-Directed Graph</h2><ul><li>Description: Shows character co-occurence, related character in closer<br>proximity and unrelated characters are farther apart.</li><li>Example: <img src="https://camo.githubusercontent.com/d7b97d7c0873e949f827918763174efcca6c4a5f/687474703a2f2f64336a732e6f72672f65782f666f7263652e706e67" alt=""></li><li>Variants: <a href="https://bl.ocks.org/mbostock/4600693" target="_blank" rel="noopener">Curved Links</a>, <a href="http://bost.ocks.org/mike/fisheye/" target="_blank" rel="noopener">Fisheye<br>Distoration</a>, <a href="http://bost.ocks.org/mike/miserables/" target="_blank" rel="noopener">Matrix diagram</a><br>, <a href="http://mbostock.github.io/d3/talk/20111116/force-collapsible.html" target="_blank" rel="noopener">Collapse Force layout</a><br>, <a href="http://bl.ocks.org/MoritzStefaner/1377729" target="_blank" rel="noopener">Force-based label</a></li></ul><h2 id="Sector-Comparation"><a href="#Sector-Comparation" class="headerlink" title="Sector Comparation"></a><a href="http://www.brightpointinc.com/united-states-trade-deficit/" target="_blank" rel="noopener">Sector Comparation</a></h2><ul><li>Description: Comparation between two main properties with some sub propritis.</li><li>Example: <img src="https://camo.githubusercontent.com/c2826f9a0c78f2f0404b094c891348b72d38d54e/687474703a2f2f7777772e627269676874706f696e74696e632e636f6d2f696e7465726163746976652f696d616765732f446566696369745f32303270782e706e67" alt=""></li></ul><h1 id="A-B-and-C"><a href="#A-B-and-C" class="headerlink" title="A, B and C"></a>A, B and C</h1><h2 id="Circle-gram"><a href="#Circle-gram" class="headerlink" title="Circle gram"></a>Circle gram</h2><ul><li>Description:(X,Y)-&gt;Z, Z use circle and the area stands for Z value.</li><li>Example: <img src="https://camo.githubusercontent.com/d5cc8b32409a9d498d83ce13c3f13ec7ac664601/687474703a2f2f6e657572616c656e67722e636f6d2f61736966722f6a6f75726e616c732f6a6f75726e616c732e706e67" alt=""><br><img src="https://camo.githubusercontent.com/3fb6699cd8462e7a82b69c04ac5cb37b968c0f09/687474703a2f2f64336a732e6f72672f65782f66616365626f6f6b2d69706f2e706e67" alt=""></li></ul><h1 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h1><p>The following charts are used for showing data which has a tree data structure.</p><h2 id="Dendrogram"><a href="#Dendrogram" class="headerlink" title="Dendrogram"></a>Dendrogram</h2><ul><li>Description: Leaf nodes of the tree at the same depth, are aligned on the<br>right edge.</li><li>Example: <img src="https://camo.githubusercontent.com/e1a1948f0bcfa095d54793afd3ab96af97731773/687474703a2f2f64336a732e6f72672f65782f636c75737465722e706e67" alt=""></li></ul><h2 id="Hierarchical-Edge-Bundling"><a href="#Hierarchical-Edge-Bundling" class="headerlink" title="Hierarchical Edge Bundling"></a>Hierarchical Edge Bundling</h2><ul><li>Exampel: <img src="https://camo.githubusercontent.com/75572c7b80dabb1a0984bd8ea9d3ee16c5200fe3/687474703a2f2f64336a732e6f72672f65782f62756e646c652e706e67" alt=""></li></ul><h2 id="Treemap"><a href="#Treemap" class="headerlink" title="Treemap"></a>Treemap</h2><ul><li>Description: A treemap recursively subdivideds area into rectangles, the area<br>of any node in the tree corresponds to its value.</li><li>Example: <img src="https://camo.githubusercontent.com/e6612268ca90a8c2f6d1da62f85d7d86616c37de/687474703a2f2f64336a732e6f72672f65782f747265656d61702e706e67" alt=""></li></ul><h2 id="Partition-layout"><a href="#Partition-layout" class="headerlink" title="Partition layout"></a>Partition layout</h2><ul><li>Description: A treemap recursively subdivideds in horizational.</li><li>Example: <img src="https://camo.githubusercontent.com/48f41725f95dad3f65f65e5f47c1b70e932be48c/687474703a2f2f64336a732e6f72672f65782f706172746974696f6e2d7a6f6f6d2e706e67" alt=""></li></ul><h2 id="Circle-packing"><a href="#Circle-packing" class="headerlink" title="Circle packing"></a>Circle packing</h2><ul><li>Description: Use containment to represent the hierarchy, the area of circle<br>can stand for item value, it better reveals the hierarchy than treemap.</li><li>Example: <img src="https://camo.githubusercontent.com/428c04c95f2a18ce7178d9d6135f1eab8df10ebd/687474703a2f2f64336a732e6f72672f65782f7061636b2e706e67" alt=""></li><li>Variants: <a href="http://mbostock.github.com/d3/talk/20111116/pack-hierarchy.html" target="_blank" rel="noopener">Zoomable Pack layout</a></li></ul><h2 id="Sunburst"><a href="#Sunburst" class="headerlink" title="Sunburst"></a>Sunburst</h2><ul><li>Description: A treemap has a radial layout, all the root nodes are at the<br>center.</li><li>Exampel: <img src="https://camo.githubusercontent.com/1415e2af369262e466534480edbc7baa883e5b58/687474703a2f2f64336a732e6f72672f65782f73756e62757273742e706e67" alt=""></li><li>Variants: <a href="http://www.jasondavies.com/coffee-wheel/" target="_blank" rel="noopener">Zoomable Sunburst</a>, <a href="http://bl.ocks.org/kerryrodden/7090426" target="_blank" rel="noopener">Sequences sunburst</a></li></ul><h2 id="Node-Link-Tree"><a href="#Node-Link-Tree" class="headerlink" title="Node-Link Tree"></a>Node-Link Tree</h2><ul><li>Description: The depth of nodes is computed by distance from the root, leading<br>to a ragged appearance.</li><li>Example: <img src="https://camo.githubusercontent.com/e646acd936244a6db8a140fb0e1e421d95b97d8e/687474703a2f2f64336a732e6f72672f65782f747265652e706e67" alt=""></li></ul><h1 id="A-B-C-…-gt-D-E-F-…-with-intermediate-nodes"><a href="#A-B-C-…-gt-D-E-F-…-with-intermediate-nodes" class="headerlink" title="A, B , C, … -&gt; D, E, F, … with intermediate nodes."></a>A, B , C, … -&gt; D, E, F, … with intermediate nodes.</h1><h2 id="Sankey-Diagrams"><a href="#Sankey-Diagrams" class="headerlink" title="Sankey Diagrams"></a><a href="https://bost.ocks.org/mike/sankey/" target="_blank" rel="noopener">Sankey Diagrams</a></h2><ul><li>Description: Sankey diagrams visualize the magnitude of flow between nodes in<br>a network. This intricate diagram shows a possible scenario for UK energy<br>production and consumption in 2050: energy supplies are on the left, and<br>demands are on the right. Intermediate nodes group related forms of production<br>and show how energy is converted and transmitted before it is consumed (or<br>lost!). The thickness of each link encodes the amount of flow from source to<br>target.</li><li>Example: <img src="https://camo.githubusercontent.com/d9abb5b2b474c0e37728abedb9ba722f8b6e4f24/687474703a2f2f64336a732e6f72672f65782f73616e6b65792e706e67" alt=""></li></ul><h1 id="Compare-n-properties"><a href="#Compare-n-properties" class="headerlink" title="Compare n properties"></a>Compare n properties</h1><h2 id="Time-Series-Comparation"><a href="#Time-Series-Comparation" class="headerlink" title="Time Series Comparation"></a>Time Series Comparation</h2><ul><li>Description: None.</li><li>Example: <img src="https://camo.githubusercontent.com/aa4653694ba96e7991206963a698584169d54204/68747470733a2f2f676973742e6769746875622e636f6d2f6d6172756662642f373139313334302f7261772f616230353765656639323237653534393834333163303330633661643530343863623332366133612f7468756d626e61696c2e706e67" alt=""></li></ul><h2 id="Streamgraph"><a href="#Streamgraph" class="headerlink" title="Streamgraph"></a>Streamgraph</h2><ul><li>Description: None.</li><li>Example: <img src="https://camo.githubusercontent.com/3cbc8c7898d1336e83e499cb66274c15e63f65bf/687474703a2f2f64336a732e6f72672f65782f73747265616d2e706e67" alt=""></li></ul><h2 id="Bar-Line-Scatter-Stacked-bar-etc"><a href="#Bar-Line-Scatter-Stacked-bar-etc" class="headerlink" title="Bar, Line, Scatter, Stacked bar, etc."></a>Bar, Line, Scatter, Stacked bar, etc.</h2><h2 id="Radial-plot"><a href="#Radial-plot" class="headerlink" title="Radial plot"></a>Radial plot</h2><ul><li>Description: Boxplot for continuous data.</li><li>Example: <img src="https://camo.githubusercontent.com/f17a69dcf4d6cf3020fc77016844d6c46ae5419a/687474703a2f2f626c2e6f636b732e6f72672f646176696477636c696e2f7261772f61643564313364623236306361656666653962332f7468756d626e61696c2e706e67" alt=""></li></ul><h2 id="Radar-Chart"><a href="#Radar-Chart" class="headerlink" title="Radar Chart"></a>Radar Chart</h2><ul><li>Description: Comparation between n properties, all of them have the save<br>sacle.</li><li>Example: <img src="https://raw.githubusercontent.com/nbremer/thumbnails/master/D3%20Radar%20Chart%20Redesign.png" alt=""></li></ul><h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><h2 id="Choropleth"><a href="#Choropleth" class="headerlink" title="Choropleth"></a><a href="https://bl.ocks.org/mbostock/4060606" target="_blank" rel="noopener">Choropleth</a></h2><ul><li>Description: Color stands for value and showd in a geo-map.</li><li>Example: <img src="https://camo.githubusercontent.com/0afefbc191693b8ecaea58cda0b587a908fc0174/687474703a2f2f64336a732e6f72672f65782f63686f726f706c6574682e706e67" alt=""></li></ul><p>Not all, visit <a href="https://github.com/d3/d3/wiki/Gallery" target="_blank" rel="noopener">https://github.com/d3/d3/wiki/Gallery</a> for more examples.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;style&gt;
img{height:200px;}
&lt;/style&gt;


&lt;p&gt;A simple list of chart types and data structure.&lt;/p&gt;
&lt;h1 id=&quot;Single-property&quot;&gt;&lt;a href=&quot;#Single-prop
      
    
    </summary>
    
      <category term="Others" scheme="http://dequn.github.io/categories/Others/"/>
    
    
      <category term="d3" scheme="http://dequn.github.io/tags/d3/"/>
    
  </entry>
  
  <entry>
    <title>就折腾到这儿吧</title>
    <link href="http://dequn.github.io/2016/12/27/jiu-zhe-teng-dao-zhe-er-ba/"/>
    <id>http://dequn.github.io/2016/12/27/jiu-zhe-teng-dao-zhe-er-ba/</id>
    <published>2016-12-27T11:00:58.000Z</published>
    <updated>2017-08-24T12:49:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>上上周从百度搜索部Rank组面试回来之后，就有点不安，三面的面试官直接告诉我这面的表现不好，让她很担心。说这句话分明是让我很担心，核心部门还是很值得期待的。一周都没有音信，想必是挂掉了，不曾想今天接到HR电话联系offer事宜，终于可以把心放肚子里了。</p><p>今年四月份的时候面了一次腾讯实习，不意外地终止在一面。回来之后那个惶恐啊，突然间发现以自身的能力什么工作都找不到，但同时还欠着小论文没写，刚换了题目还没有看文献，一下子都不知道该做什么了。接下来的几个月也是最痛苦的，东一棒槌西一榔头，压根没有主心骨。</p><p>好在暑期的时候终于把小论文凑完了，赶紧刷算法，面试也都陆陆续续的开始了，准备了不到一个月，就进入秋招高峰期，也就没有再静心准备了。笔试一个接着一个，面试仍还是倒在一面。腾讯地图部门提前批感觉还不错，结果不行，微店一面感觉不好，挂掉…从来不知道二面是什么样子，更担心——妈的这得到什么时候才能找到工作。</p><p>面京东的时候比较顺利，虽然在一二面中已经知道岗位不是我想做的，但为了保底也要面下去，滑稽的是HR面挂了…真是见鬼了，短短5分钟的电面，我想犯错都难啊。后来华为也是，两面觉得非常顺利，不料仍然是failed，莫非真如师兄所说的：我犯了低级错误？但已然不记得了…</p><p>百度是第一个给offer的公司，也是唯一一个给了两次offer的。9月份校招面试机器学习，一面就挂了，面试官觉得coding还不错，推荐我去面开发测试，并给了一点职业规划的建议（真是好人啊，哈哈），后来顺利通过开发测试的三轮面试，所以说多数人当天都是三轮面试，我却面了四轮，也是够有趣的。之后觉得岗位不太合适就拒绝掉了，需要说明的是我一直是以岗位为目标的，对公司没有什么要求，所以后面一个小公司给了数据挖掘的岗位觉得还不错就签了，搜狗面试要我进去做web开发，犹豫了一下之后就以“目前还没有在web开发上有较清晰的职业规划”婉拒了，也就不意外的无果而终了。</p><p>现在想来真是作，为什么非得一根筋的非得去面数据挖掘\机器学习，压根没有任何相关的项目经验怎么去面！在签了小公司的数据挖掘岗位后进入观望阶段，赶紧的补补课，事实上囫囵吐枣半懂不懂地学习了一段时间后就也没再坚持。直到看到百度搜索部门的补招信息，并意外的有面试机会，真心不容易。一二面还不错，三面面试官在说了我表现不好之后还补充一句：其实你的简历在机器筛选的时候就没能通过，后来看你项目经历涉及的方面比较多，所以才又给提出来看看你的综合能力…</p><p>简历平平，因为能力、经历实在是太一般，也难怪很多公司始终没给我面试的机会。大师兄没少给加油打气，导致我自己都快相信他说的了（肯定没问题！），思考后才明白:鼓励不是你已经做到了，而是需要做到的，我们太容易认为那些鼓励的话都已是事实了。</p><p>这已经是我能折腾到的最好结果了，纯粹是撞运气的结果，论真实力怎么也不可能胜任的。虽然我也是个百度黑，很多人也骂它，但能“委身”于这样的现实也很满足了。接下来就是有个明确的规划和计划，总不能跳离的时候还是平平吧？</p><p>感谢给我内推的师兄、师姐和一些个招聘平台，感谢老板给我开放、自由的时间和空间，感谢周围的小伙伴儿，最后感谢一下面试官吧。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上上周从百度搜索部Rank组面试回来之后，就有点不安，三面的面试官直接告诉我这面的表现不好，让她很担心。说这句话分明是让我很担心，核心部门还是很值得期待的。一周都没有音信，想必是挂掉了，不曾想今天接到HR电话联系offer事宜，终于可以把心放肚子里了。&lt;/p&gt;
&lt;p&gt;今年四
      
    
    </summary>
    
      <category term="个人日记" scheme="http://dequn.github.io/categories/%E4%B8%AA%E4%BA%BA%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="面试" scheme="http://dequn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>Zeppelin 安装配置的一些问题</title>
    <link href="http://dequn.github.io/2016/11/20/zeppelin-installation-and-settings/"/>
    <id>http://dequn.github.io/2016/11/20/zeppelin-installation-and-settings/</id>
    <published>2016-11-20T06:15:30.000Z</published>
    <updated>2017-08-24T15:01:09.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-版本问题"><a href="#1-版本问题" class="headerlink" title="1.版本问题"></a>1.版本问题</h1><p>Zeppelin 从0.6.1版本开始，默认是基于 Spark 2.x 和 Scala 2.11版本进行编译的，亲测 Zeppelin 0.6.2与 Spark 1.6.x 版本是不兼容的，导致 Saprk Interpreters 不能正确运行，如果需要安装在老版本上的，需要自己从源码编译，可以指定 Spark、Hadoop等版本参数，可以参考 <a href="http://zeppelin.apache.org/docs/snapshot/install/build.html" target="_blank" rel="noopener">http://zeppelin.apache.org/docs/snapshot/install/build.html</a> ，如果是0.6.0版本，可与 Spark 1.6.x 之前的兼容运行。</p><h1 id="2-Phoenix-thin-连接问题"><a href="#2-Phoenix-thin-连接问题" class="headerlink" title="2.Phoenix-thin 连接问题"></a>2.Phoenix-thin 连接问题</h1><p><strong><em>2017年1月3号更新</em></strong>：</p><p>Phoenix for Spark 2.x Integration的补丁已经出来了，可以直接加载为DataFrame而不用通过JDBC的方式连接数据库了，会获得更高的效率。Pheonix for Spark 2.x 版本的问题可以参见<a href="https://issues.apache.org/jira/browse/PHOENIX-3333" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/PHOENIX-3333</a>，如何使用可以参见文章<a href="http://dequn.github.io/2016/11/08/phoenix-spark-setting/">Spark 连接 Phoenix 配置</a>。</p><hr><p>Zeppelin 从0.6.0版本开始支持 Phoenix 连接，<a href="http://www.phoenix.apache.org" target="_blank" rel="noopener">Phoenix</a>默认是在jdbc interpreter 中配置的，配置过程可以参考 <a href="https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix" target="_blank" rel="noopener">https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix</a> ，<strong>注意一定要在Dependencies中添加artifact 依赖，如果从 maven远程库下载太慢，可以直接填写本地<code>phoenix-&lt;version&gt;-thin-client.jar</code>文件路径，或者把 jar 文件复制到路径<code>ZEPPELIN_HOME/interpreter/jdbc</code>下。</strong></p><p>但是如果使用的是phoenix-thin 连接，会报错误</p><blockquote><p>No suitable driver found for <a href="http://localhost:8765" target="_blank" rel="noopener">http://localhost:8765</a></p></blockquote><p>原因可以参见 <a href="https://github.com/apache/zeppelin/pull/1442" target="_blank" rel="noopener">https://github.com/apache/zeppelin/pull/1442</a> ，提供我已经编译好的 <a href="http://obqjd695a.bkt.clouddn.com/zeppelin-jdbc-0.6.2.jar" target="_blank" rel="noopener">zeppelin-jdbc-0.6.2.jar</a>，替换掉 <strong><code>ZEPPELIN_HOME/interpreter/jdbc</code></strong> 下边对应的同名文件即可。</p><h3 id="文件下载-zeppelin-jdbc-0-6-2-jar"><a href="#文件下载-zeppelin-jdbc-0-6-2-jar" class="headerlink" title="文件下载:zeppelin-jdbc-0.6.2.jar"></a>文件下载:<a href="http://obqjd695a.bkt.clouddn.com/zeppelin-jdbc-0.6.2.jar" target="_blank" rel="noopener">zeppelin-jdbc-0.6.2.jar</a></h3><h1 id="3-zeppelin中用-scala-加载-jdbc-数据问题"><a href="#3-zeppelin中用-scala-加载-jdbc-数据问题" class="headerlink" title="3.zeppelin中用 scala 加载 jdbc 数据问题"></a>3.zeppelin中用 scala 加载 jdbc 数据问题</h1><p><strong><em>2017年1月3号更新</em></strong>：</p><p>好久没有使用，重新折腾了一下，发现<strong>org.apache.hadoop.tracing.SpanReceiverHost.get(xxx)报错</strong>是由于Zeppelin提供的Hadoop版本和Spark编译时指定的版本不一致引起，只需要使用$SPARK_HOME/jars/hadoop-annotations-2.7.3.jar、hadoop-auth-2.7.3.jar、hadoop-common-2.7.3.jar替换掉$ZEPPELIN_HOME/lib下的对应文件即可。具体可以参考<a href="http://blog.csdn.net/lsshlsw/article/details/53768756" target="_blank" rel="noopener">Zeppelin 0.6.2 使用spark2.x 的一些错误处理</a>。</p><hr><p>刚开始使用的是Spark 2.0.1，使用下面的代码用 jdbc 读取数据库中的数据，发现总是报错，第一个关于 xxx.hive.ql.xxx 的错误，在 interpreter 的配置中将<code>zeppelin.spark.useHiveContext</code>项设置为<code>false</code>即可，<del>如果后面org.apache.hadoop.tracing.SpanReceiverHost.get(xxx)还继续报错，可以 <strong>升级 Spark2.0.2试试</strong> ，我是无意在笔记本上使用 Spark2.0.2 发现的 。</del></p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">val <span class="keyword">jdbcDf </span>= spark.read</span><br><span class="line">.format(<span class="string">"jdbc"</span>)</span><br><span class="line">.option(<span class="string">"driver"</span>,<span class="string">"org.apache.phoenix.queryserver.client.Driver"</span>)</span><br><span class="line">.option(<span class="string">"url"</span>,<span class="string">"jdbc:phoenix:thin:url=http://localhost:8765;serialization=PROTOBUF"</span>)</span><br><span class="line">.option(<span class="string">"dbtable"</span>,<span class="string">"bigjoy.imos"</span>)</span><br><span class="line">.load()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">java.lang.RuntimeException: </span><span class="keyword">java.lang.RuntimeException: </span>Unable to <span class="keyword">instantiate </span><span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.client.HiveClientImpl.&lt;init&gt;(HiveClientImpl.scala:189)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">  <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.<span class="keyword">java:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.<span class="keyword">java:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState$$anon$1.&lt;init&gt;(HiveSessionState.scala:63)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:382)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:143)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:122)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">47</span> elided</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.RuntimeException: </span>Unable to <span class="keyword">instantiate </span><span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:86)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">69</span> more</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.reflect.InvocationTargetException: </span><span class="keyword">java.lang.NoSuchMethodError: </span><span class="keyword">org.apache.hadoop.tracing.SpanReceiverHost.get(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Lorg/apache/hadoop/tracing/SpanReceiverHost;</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">  <span class="built_in">at</span> sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.<span class="keyword">java:62)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.<span class="keyword">java:45)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">75</span> more</span><br><span class="line">Caused <span class="keyword">by: </span><span class="keyword">java.lang.NoSuchMethodError: </span><span class="keyword">org.apache.hadoop.tracing.SpanReceiverHost.get(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Lorg/apache/hadoop/tracing/SpanReceiverHost;</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:634)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:619)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileSystem.get(FileSystem.java:354)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:104)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:140)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:146)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:159)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:177)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:600)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:620)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:199)</span></span><br><span class="line"><span class="keyword"> </span> <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:74)</span></span><br><span class="line"><span class="keyword"> </span> ... <span class="number">80</span> more</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1]: <a href="http://zeppelin.apache.org/docs/snapshot/install/build.html" target="_blank" rel="noopener">Zeppelin 源码编译</a><br>[2]: <a href="https://zeppelin.apache.org/docs/0.6.2/interpreter/jdbc.html#phoenix" target="_blank" rel="noopener">Zeppelin Phoenix Interpreter 配置</a><br>[3]: <a href="https://github.com/apache/zeppelin/pull/1442" target="_blank" rel="noopener">ZEPPELIN-1459: Zeppelin JDBC URL properties mangled</a><br>[4]: <a href="http://blog.csdn.net/lsshlsw/article/details/53768756" target="_blank" rel="noopener">Zeppelin 0.6.2 使用spark2.x 的一些错误处理</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-版本问题&quot;&gt;&lt;a href=&quot;#1-版本问题&quot; class=&quot;headerlink&quot; title=&quot;1.版本问题&quot;&gt;&lt;/a&gt;1.版本问题&lt;/h1&gt;&lt;p&gt;Zeppelin 从0.6.1版本开始，默认是基于 Spark 2.x 和 Scala 2.11版本进行编译
      
    
    </summary>
    
      <category term="Zeppelin" scheme="http://dequn.github.io/categories/Zeppelin/"/>
    
    
      <category term="Phoenix" scheme="http://dequn.github.io/tags/Phoenix/"/>
    
      <category term="Spark" scheme="http://dequn.github.io/tags/Spark/"/>
    
      <category term="Zeppelin" scheme="http://dequn.github.io/tags/Zeppelin/"/>
    
  </entry>
  
  <entry>
    <title>Intellij IDEA 中调试 Spark Application</title>
    <link href="http://dequn.github.io/2016/11/19/debug-spark-in-intellij/"/>
    <id>http://dequn.github.io/2016/11/19/debug-spark-in-intellij/</id>
    <published>2016-11-19T02:12:47.000Z</published>
    <updated>2017-08-24T14:56:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>Spark 新手一名，同样也是 Scala 菜鸟，由于对这两个都不是特别熟悉，所以希望能在 IDE中 coding 和 debug，但是调试 Spark 程序和往常接触过的不一样，并且有一些观念上的错误，总结一下。</p><h1 id="坑一：网络代理"><a href="#坑一：网络代理" class="headerlink" title="坑一：网络代理"></a>坑一：网络代理</h1><p>程序写好以后，可以直接 debug 的(只限于 spark.master= local[*]的场景)，由于使用了 ShadowSocks 全局代理翻墙，最初一直报错，Google 了好大会儿也没找到问原因，后来才猛的想起代理还开着，而 hosts 文件中恰恰没有 localhost 映射到127.0.0.1中，修改 hosts，解决。直接 debug 可以使用较小的数据进行测试，不是非得网上众多教程那样得 sbt package -&gt; spark-submit -&gt; Remote Debug 那样不方便。</p><h1 id="坑二：worksheet-运行？"><a href="#坑二：worksheet-运行？" class="headerlink" title="坑二：worksheet 运行？"></a>坑二：worksheet 运行？</h1><p>虽然 spark-shell也提供了交互式命令行，尝试代码非常方便，不用每次都 debug 启动 sprak，那样效率太低。然而保存代码就比较麻烦了，因此想着能不能使用 scala worksheet来运行，这样结果也即时可见，代码也不会丢失，尝试了一番，发现不行，有高手解释为：spark 的 REPL 解释器和 Scala 的不一样，因此里边是运行不了 spark 程序的。难道就没有其他办法了吗？有的，采用Scala Console 代替，在文件上右键点击，选择 Run Scala Console 即可，可以与把文件里的代码发送给 console 运行，虽然不如 worksheet 方便，但也好过 spark-sheel 或者每次都启动 debug了。</p><h1 id="坑三：debug-on-spark-cluster"><a href="#坑三：debug-on-spark-cluster" class="headerlink" title="坑三：debug on spark cluster"></a>坑三：debug on spark cluster</h1><p>这个和坑一有些类似，在老板的三台机器上搭建了一个小集群，并以 standlone cluster 方式运行，于是就直接在 cluster 上debug 吧，获取 sparkContext 的方式如代码所示<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val spark = SparkSession.builder().<span class="literal">master</span>(<span class="string">"spark://192.168.6.131:7077"</span>).appName(<span class="string">"bigjoy"</span>).getOrCreate()</span><br></pre></td></tr></table></figure></p><p>在控制台中的 Log 如下，不断地停掉和开启 Executor，心想也不至于吧，数据量没那么大呀！</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARN TaskSchedulerImpl: Initial job has<span class="built_in"> not </span>accepted any resources;<span class="built_in"> check </span>your cluster UI to ensure that workers are registered<span class="built_in"> and </span>have sufficient resources</span><br></pre></td></tr></table></figure><p>于是去检查 spark UI 的 log, 看到下面的错误</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java<span class="selector-class">.lang</span><span class="selector-class">.reflect</span><span class="selector-class">.UndeclaredThrowableException</span></span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.security</span><span class="selector-class">.UserGroupInformation</span><span class="selector-class">.doAs</span>(UserGroupInformation<span class="selector-class">.java</span>:<span class="number">1713</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span><span class="selector-class">.runAsSparkUser</span>(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">70</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$.run(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">174</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$.main(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">270</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span><span class="selector-class">.main</span>(CoarseGrainedExecutorBackend.scala)</span><br><span class="line">Caused by: org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkException</span>: Exception thrown <span class="keyword">in</span> awaitResult</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">77</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">75</span>)</span><br><span class="line">at scala<span class="selector-class">.runtime</span><span class="selector-class">.AbstractPartialFunction</span><span class="selector-class">.apply</span>(AbstractPartialFunction<span class="selector-class">.scala</span>:<span class="number">36</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span><span class="variable">$addMessageIfTimeout</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">59</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span>$<span class="variable">$anonfun</span><span class="variable">$addMessageIfTimeout</span>$<span class="number">1</span>.applyOrElse(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">59</span>)</span><br><span class="line">at scala.PartialFunction<span class="variable">$OrElse</span>.apply(PartialFunction<span class="selector-class">.scala</span>:<span class="number">167</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcTimeout</span><span class="selector-class">.awaitResult</span>(RpcTimeout<span class="selector-class">.scala</span>:<span class="number">83</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.RpcEnv</span><span class="selector-class">.setupEndpointRefByURI</span>(RpcEnv<span class="selector-class">.scala</span>:<span class="number">88</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.CoarseGrainedExecutorBackend</span>$<span class="variable">$anonfun</span><span class="variable">$run</span>$<span class="number">1</span>.apply<span class="variable">$mcV</span><span class="variable">$sp</span>(CoarseGrainedExecutorBackend<span class="selector-class">.scala</span>:<span class="number">188</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span>$<span class="variable">$anon</span>$<span class="number">1</span>.run(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">71</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkHadoopUtil</span>$<span class="variable">$anon</span>$<span class="number">1</span>.run(SparkHadoopUtil<span class="selector-class">.scala</span>:<span class="number">70</span>)</span><br><span class="line">at java<span class="selector-class">.security</span><span class="selector-class">.AccessController</span><span class="selector-class">.doPrivileged</span>(Native Method)</span><br><span class="line">at javax<span class="selector-class">.security</span><span class="selector-class">.auth</span><span class="selector-class">.Subject</span><span class="selector-class">.doAs</span>(Subject<span class="selector-class">.java</span>:<span class="number">422</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.security</span><span class="selector-class">.UserGroupInformation</span><span class="selector-class">.doAs</span>(UserGroupInformation<span class="selector-class">.java</span>:<span class="number">1698</span>)</span><br><span class="line">... <span class="number">4</span> more</span><br><span class="line">Caused by: java<span class="selector-class">.io</span><span class="selector-class">.IOException</span>: Failed to connect to /<span class="number">192.168</span>.<span class="number">1.105</span>:<span class="number">51340</span></span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.network</span><span class="selector-class">.client</span><span class="selector-class">.TransportClientFactory</span><span class="selector-class">.createClient</span>(TransportClientFactory<span class="selector-class">.java</span>:<span class="number">228</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.network</span><span class="selector-class">.client</span><span class="selector-class">.TransportClientFactory</span><span class="selector-class">.createClient</span>(TransportClientFactory<span class="selector-class">.java</span>:<span class="number">179</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.NettyRpcEnv</span><span class="selector-class">.createClient</span>(NettyRpcEnv<span class="selector-class">.scala</span>:<span class="number">197</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.Outbox</span>$<span class="variable">$anon</span>$<span class="number">1</span>.call(Outbox<span class="selector-class">.scala</span>:<span class="number">191</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rpc</span><span class="selector-class">.netty</span><span class="selector-class">.Outbox</span>$<span class="variable">$anon</span>$<span class="number">1</span>.call(Outbox<span class="selector-class">.scala</span>:<span class="number">187</span>)</span><br><span class="line">at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.FutureTask</span><span class="selector-class">.run</span>(FutureTask<span class="selector-class">.java</span>:<span class="number">266</span>)</span><br><span class="line">at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="selector-class">.runWorker</span>(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">1142</span>)</span><br><span class="line">at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="variable">$Worker</span>.run(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">617</span>)</span><br><span class="line">at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">745</span>)</span><br><span class="line">Caused by: java<span class="selector-class">.net</span><span class="selector-class">.NoRouteToHostException</span>: No route to host: /<span class="number">192.168</span>.<span class="number">1.105</span>:<span class="number">51340</span></span><br><span class="line">at sun<span class="selector-class">.nio</span><span class="selector-class">.ch</span><span class="selector-class">.SocketChannelImpl</span><span class="selector-class">.checkConnect</span>(Native Method)</span><br><span class="line">at sun<span class="selector-class">.nio</span><span class="selector-class">.ch</span><span class="selector-class">.SocketChannelImpl</span><span class="selector-class">.finishConnect</span>(SocketChannelImpl<span class="selector-class">.java</span>:<span class="number">717</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.socket</span><span class="selector-class">.nio</span><span class="selector-class">.NioSocketChannel</span><span class="selector-class">.doFinishConnect</span>(NioSocketChannel<span class="selector-class">.java</span>:<span class="number">224</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.AbstractNioChannel</span><span class="variable">$AbstractNioUnsafe</span>.finishConnect(AbstractNioChannel<span class="selector-class">.java</span>:<span class="number">289</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKey</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">528</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKeysOptimized</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">468</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.processSelectedKeys</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">382</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.channel</span><span class="selector-class">.nio</span><span class="selector-class">.NioEventLoop</span><span class="selector-class">.run</span>(NioEventLoop<span class="selector-class">.java</span>:<span class="number">354</span>)</span><br><span class="line">at io<span class="selector-class">.netty</span><span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.SingleThreadEventExecutor</span>$<span class="number">2</span>.run(SingleThreadEventExecutor<span class="selector-class">.java</span>:<span class="number">111</span>)</span><br><span class="line">... <span class="number">1</span> more</span><br></pre></td></tr></table></figure><p>看到 IP:192.168.1.105 后猛然想起，个人使用的笔记本网络连接的是办公室的路由器，而办公室的路由器的 ip 才是和集群的机器 Ip 在同一局域网中，中间跨了级！办公室的路由器又没有设置端口映射，难怪找不到！改为使用单位的无线路由（和集群一个局域网）后就没有此错误了！或者也可以设置一下小路由器的端口映射！</p><h1 id="坑四：sbt-或-maven-中的依赖版本（包括小版本）一定要与集群一致"><a href="#坑四：sbt-或-maven-中的依赖版本（包括小版本）一定要与集群一致" class="headerlink" title="坑四：sbt 或 maven 中的依赖版本（包括小版本）一定要与集群一致"></a>坑四：sbt 或 maven 中的依赖版本（包括小版本）一定要与集群一致</h1><p>使用坑三中的 debug on cluster, 由于很早建立的 maven 工程，采用的是 org.apache.spark:spark-core_2.1:2.0.1依赖，后来搭建集群的时候2.0.2版本已经发布，所以采用了最新的，由于大版本一致，所以就没有在意，debug 的时候报以下错误：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.InvalidClassException: org.apache.spark.executor.TaskMetrics; <span class="keyword">local</span> <span class="built_in">class</span> incompatible: stream classdesc serialVersionUID = <span class="number">-6966587383730940799</span>, <span class="keyword">local</span> <span class="built_in">class</span> serialVersionUID = <span class="number">-2231953621568687904</span></span><br></pre></td></tr></table></figure><p>此问题由小版本不一致导致，说来也正常，向下兼容很正常，但向上的，呵呵，所以保持一致吧！</p><h1 id="坑五：找不到类？"><a href="#坑五：找不到类？" class="headerlink" title="坑五：找不到类？"></a>坑五：找不到类？</h1><p>由于工程采用 maven 构建，我使用了 phoenix 的依赖，当 spark.master=local[*]的时候，调试没有任何问题，但是当把 spark.master 设置为 spark://spark-master:7077也就是采用集群的时候，会提示除 spark 自带的（core, sql,mllib, stream）库之外，其他的都提示找不到，解决方案除了 <strong> 1）参考网上的远程调试外</strong> ，现提供另一种方式，<strong> 2)类似于 Hadoop的调试方式</strong></p><h2 id="1-设置-artifact"><a href="#1-设置-artifact" class="headerlink" title="1.设置 artifact"></a>1.设置 artifact</h2><p>File -&gt; Project Structre, 在 Artifacts 里边新建一个 jar 包，选择主类，在 Output Layout 中可以删除 spark 相关的（因为集群中已经有了，其他集群中CASSPATH 包含的都可以省掉，减少 jar包体积），最后确认即可。</p><p><img src="http://obqjd695a.bkt.clouddn.com/new-artifact.png" alt=""><br><img src="http://obqjd695a.bkt.clouddn.com/artifact-setting.png" alt=""><br><img src="http://obqjd695a.bkt.clouddn.com/artifact-jar-setting.png" alt=""></p><h2 id="2-spark-添加-jar-依赖"><a href="#2-spark-添加-jar-依赖" class="headerlink" title="2.spark 添加 jar 依赖"></a>2.spark 添加 jar 依赖</h2><p>只需要个 sparkContext 添加 jar包即可，代码如下</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> val spark = SparkSession.builder().master(<span class="string">"spark://192.168.6.131:7077"</span>).appName(<span class="string">"bigjoy"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">//注意路径是编译后的路径</span></span><br><span class="line">    spark<span class="selector-class">.sparkContext</span><span class="selector-class">.addJar</span>(<span class="string">"/Users/dq/IdeaProjects/subject/out/artifacts/analysis_jar/analysis.jar"</span>)</span><br></pre></td></tr></table></figure><p>在debug 前，先 Build -&gt; Build Artifacts -&gt; xxx.jar，把代码中的路径替换为实际的路径，然后就可以像其他普通的代码一样调试了，不过发现运行的比较慢，因为没有与远程调试的进行对比，所以哪个更好一些就暂不能下结论了，不过这个免去了上传 jar 包、spark-submit、remote debug 等过程，简单一些。</p><p>就先总结这么多吧！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Spark 新手一名，同样也是 Scala 菜鸟，由于对这两个都不是特别熟悉，所以希望能在 IDE中 coding 和 debug，但是调试 Spark 程序和往常接触过的不一样，并且有一些观念上的错误，总结一下。&lt;/p&gt;
&lt;h1 id=&quot;坑一：网络代理&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="Spark" scheme="http://dequn.github.io/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://dequn.github.io/tags/Spark/"/>
    
      <category term="Intellij IDEA" scheme="http://dequn.github.io/tags/Intellij-IDEA/"/>
    
  </entry>
  
  <entry>
    <title>Spark 连接 Phoenix 配置</title>
    <link href="http://dequn.github.io/2016/11/08/phoenix-spark-setting/"/>
    <id>http://dequn.github.io/2016/11/08/phoenix-spark-setting/</id>
    <published>2016-11-08T06:06:40.000Z</published>
    <updated>2017-08-24T14:55:34.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>2017年1月3号更新：</em></strong></p><p>在Spark 2.x版本中更改了DataFrame的定义，而Phoenix4.9及以前(4.10后官方版本会修复）是在Spark1.x的环境下开发的，因此如果使用Spark2.x的环境，不能正常使用Phoenix Spark Interprter, 具体问题可以参考 <a href="https://issues.apache.org/jira/browse/PHOENIX-3333" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/PHOENIX-3333</a>，这里给出本人利用链接中的补丁编译后的phoenix，其他参考1.x版本中的配置方式即可。</p><p><a href="http://obqjd695a.bkt.clouddn.com/phoenix-4.9.0-HBase-1.2-server.jar" target="_blank" rel="noopener">phoenix-4.9.0-HBase-1.2-server.jar</a></p><p><a href="http://obqjd695a.bkt.clouddn.com/phoenix-4.9.0-HBase-1.2-client.jar" target="_blank" rel="noopener">phoenix-4.9.0-HBase-1.2-client.jar</a></p><hr><p>Phoenix 官方文档给出了如何配置Spark 连接的说明，但是由于版本更新比较快，教程已经有些过时了。</p><p>环境配置：</p><blockquote><p>Spark 1.5.2<br>Phoenix 4.8.0<br>HBase 1.1.2</p></blockquote><p>如果在 HBase上配置过 Phoenix ，服务端就不需要做任何改动了。</p><p>在<strong> Phoenix 4.8</strong> 版本中，已经没有官方示例中的<code>phoenix-&lt;version&gt;-client-spark.jar</code>的文件了，所有的客户端需要的 jar 只有一个<strong> <code>phoenix-&lt;version&gt;-client.jar</code></strong> ！</p><p>连接在 Spark 中连接Phoenix 也有两种方式：</p><h2 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h2><p>spark-shell 启动时添加 phoenix jar.</p><p>启动spark-shell 是添加参数–jars 即可<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --jars /usr/local/phoenix/phoenix<span class="number">-4.8</span><span class="number">.0</span>-HBase<span class="number">-1.1</span>-client.jar</span><br><span class="line"># ....</span><br><span class="line"># ....</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.spark._</span><br><span class="line"></span><br><span class="line"># 这一句不报错的话就说明搞定了</span><br></pre></td></tr></table></figure></p><h2 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h2><p>配置 spark-defaults.conf</p><p>如果不想每次启动都添加 –jars 参数，可以配置$SPARK_HOME/conf 下边的spark-defaults.conf文件，添加下面两个配置项，注意 jar 文件路径与名称的正确性。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.executor</span><span class="selector-class">.extraClassPath</span>      /usr/local/phoenix/phoenix-<span class="number">4.8</span>.<span class="number">0</span>-HBase-<span class="number">1.1</span>-client.jar</span><br><span class="line">spark<span class="selector-class">.driver</span><span class="selector-class">.extraClassPath</span>      /usr/local/phoenix/phoenix-<span class="number">4.8</span>.<span class="number">0</span>-HBase-<span class="number">1.1</span>-client.jar</span><br></pre></td></tr></table></figure></p><p>这样再启动spark-shell，就可以直接导入需要的包了，注意 SparkContext sc 和 SQLContext sqlContext 都已经是设置好了的，可以直接用。其他可以参考官方给出的示例。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;2017年1月3号更新：&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Spark 2.x版本中更改了DataFrame的定义，而Phoenix4.9及以前(4.10后官方版本会修复）是在Spark1.x的环境下开发的，因此如果使用Spark2.x的环
      
    
    </summary>
    
      <category term="Phoenix" scheme="http://dequn.github.io/categories/Phoenix/"/>
    
    
      <category term="spark" scheme="http://dequn.github.io/tags/spark/"/>
    
      <category term="Phoenix" scheme="http://dequn.github.io/tags/Phoenix/"/>
    
  </entry>
  
  <entry>
    <title>pyenv安装多版本 Python 过程中提示警告</title>
    <link href="http://dequn.github.io/2016/11/02/pyenv-install-with-warnings/"/>
    <id>http://dequn.github.io/2016/11/02/pyenv-install-with-warnings/</id>
    <published>2016-11-02T07:21:35.000Z</published>
    <updated>2017-08-24T14:56:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 pyenv 安装多版本 Python 时，有时候会遇到警告<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">WARNING:</span> The Python bz2 extension was not compiled. Missing the bzip2 <span class="class"><span class="keyword">lib</span>?</span></span><br><span class="line"><span class="symbol">WARNING:</span> The Python readline extension was not compiled. Missing the GNU readline <span class="class"><span class="keyword">lib</span>?</span></span><br><span class="line"><span class="symbol">WARNING:</span> The Python sqlite3 extension was not compiled. Missing the SQLite3 <span class="class"><span class="keyword">lib</span>?</span></span><br></pre></td></tr></table></figure></p><p>只需要根据提示安装就行了（CentOS7环境下):<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum <span class="keyword">install </span>readline readline-devel readline-static -y</span><br><span class="line">yum <span class="keyword">install </span>openssl openssl-devel openssl-static -y</span><br><span class="line">yum <span class="keyword">install </span>sqlite-devel -y</span><br><span class="line">yum <span class="keyword">install </span><span class="keyword">bzip2-devel </span><span class="keyword">bzip2-libs </span>-y</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在使用 pyenv 安装多版本 Python 时，有时候会遇到警告&lt;br&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
      <category term="Python" scheme="http://dequn.github.io/categories/Python/"/>
    
    
      <category term="pyenv" scheme="http://dequn.github.io/tags/pyenv/"/>
    
  </entry>
  
  <entry>
    <title>MacVim自动切换中英文输入法</title>
    <link href="http://dequn.github.io/2016/10/28/macvim-auto-im/"/>
    <id>http://dequn.github.io/2016/10/28/macvim-auto-im/</id>
    <published>2016-10-28T11:58:50.000Z</published>
    <updated>2017-08-24T15:03:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>中文用户的使用 VIM 最痛苦的就是来回切换输入法了，还好，在 OS 系统下使用 MacVim 可以设置在命令模式下禁用输入法，这样有了自动切换的效果，设置如下：</p><p><strong>第一步</strong>.在.vimrc 中设置<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">set</span> noimd</span><br><span class="line"><span class="builtin-name">set</span> <span class="attribute">imi</span>=2</span><br><span class="line"><span class="builtin-name">set</span> <span class="attribute">ims</span>=2</span><br></pre></td></tr></table></figure></p><p><strong>第二步</strong>.在 MacVim 的 Preferences 中的 Advanced 标签中，<strong>取消勾选 Draw marked text line</strong>。</p><p>这样就可以达到一个自动切换的效果（只是在命令行模式下给禁用掉了而已），这个要比设置 vimim 好用多了，vimim 延迟太大，使用非常不方便。</p><p>参考：<br>[1].<a href="https://www.v2ex.com/t/45772" target="_blank" rel="noopener">https://www.v2ex.com/t/45772</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;中文用户的使用 VIM 最痛苦的就是来回切换输入法了，还好，在 OS 系统下使用 MacVim 可以设置在命令模式下禁用输入法，这样有了自动切换的效果，设置如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;.在.vimrc 中设置&lt;br&gt;&lt;figure clas
      
    
    </summary>
    
      <category term="Others" scheme="http://dequn.github.io/categories/Others/"/>
    
    
      <category term="VIM" scheme="http://dequn.github.io/tags/VIM/"/>
    
      <category term="MacVim" scheme="http://dequn.github.io/tags/MacVim/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce 在 Map 阶段写数据库，没有 Reducer</title>
    <link href="http://dequn.github.io/2016/10/27/mapreduce-output-to-hbase-at-mapper-phase-without-reducer/"/>
    <id>http://dequn.github.io/2016/10/27/mapreduce-output-to-hbase-at-mapper-phase-without-reducer/</id>
    <published>2016-10-27T07:58:41.000Z</published>
    <updated>2017-08-24T15:03:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>手里有一张txt数据表，现在要入库(Phoenix + HBase)，因为需要对数据做一定的处理后再写入数据库，加上数据量不小，所以就想着用 MapReduce 来加速一下入库过程。</p><p>拿到一条数据处理后就可以直接入库了，那就没有必要写 Reducer 了，直接全部在 Mapper 里边完成，所以很自然地定义 DBWritable 类，作为 Mapper 的 OutputKeyClass 就行，如下这样：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.db.DBWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Created by dq on 10/27/16.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestDBWritable</span> <span class="keyword">implements</span> <span class="title">Writable</span>, <span class="title">DBWritable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> id;</span><br><span class="line">String name;</span><br><span class="line"></span><br><span class="line"><span class="comment">//getter and setter ...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(PreparedStatement preparedStatement)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line"></span><br><span class="line">preparedStatement.setInt(<span class="number">1</span>, id);</span><br><span class="line">preparedStatement.setString(<span class="number">2</span>, name);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(ResultSet resultSet)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>坑在这里</strong>:其中，<code>write(DataOutput dataOutput), readFields(DataInput dataInput)</code> 是 Writable 接口里边的函数，由于我是写数据库的，就简单的想着没有必要实现了，留空不处理，我也不读数据库，readFields(Result resultSet)就也不写啦。</p><p>Mapper 类是这样写的：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public static <span class="class"><span class="keyword">class</span> <span class="title">TestMapper</span> <span class="keyword">extends</span> <span class="title">Mapper&lt;LongWritable</span>, <span class="title">Text</span>,<span class="title">NullWritable</span>, <span class="title">TestDBWritable&gt;</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> void map(<span class="type">LongWritable</span> key, <span class="type">Text</span> value, <span class="type">Context</span> context) <span class="keyword">throws</span> <span class="type">IOException</span>, <span class="type">InterruptedException</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">TestDBWritable</span> t = <span class="keyword">new</span> <span class="type">TestWritable</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"></span><br><span class="line">context.write(<span class="type">NullWritable</span>.get(), t);</span><br><span class="line"></span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>然后是定义 Job<br><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//....</span></span><br><span class="line"><span class="keyword">job</span>.setMapOutputKeyClass(NullWritable.<span class="keyword">class</span>)<span class="comment">;</span></span><br><span class="line"><span class="keyword">job</span>.setMapOutputValueClass(TestDBWritable.<span class="keyword">class</span>)<span class="comment">;</span></span><br><span class="line"><span class="comment">//....</span></span><br></pre></td></tr></table></figure></p><p>满心欢喜地赶紧运行，还好没错，好有成就感地去查一下数据库，发现里边只是多了一个 id 为0，name 为 NULL 的记录罢了， 擦，发生了什么？还好之前搭建的是可以本地调试的环境，打个断点，看一下TestDBWritable 类的 write() 函数执行过程，发现 id 只是初始值，name 全部为NULL！ 顺着<code>context.write()</code>一路查下去，也没有发现 map 输出的时候把值给丢了呀，但进去 write 就变空值，这是肿么回事？</p><p>后来想了一下是不是因为 Writable 的两个函数没有实现的原因，带着侥幸心理实现这两个函数<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        dataOutput.writeInt(id);</span><br><span class="line">        dataOutput.writeUTF(name);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = dataInput.readInt();</span><br><span class="line">        <span class="keyword">this</span>.name = dataInput.readUTF();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>为了验证一下是不是执行了这两个函数，打上了断点调试一下，发现果然，在执行 context.write()后，执行的值 Writable 的 write 函数，然而并没有接着执行 DBWritable 的 write 函数，而是直到所有的输入数据都执行完毕后，首先执行 readFields 函数，然后又 write。单看此执行路径，<strong>虽然没有定义 reducer，但 Hadoop 还是给我们执行了一个默认的,所以在 map 输出的时候会执行写入缓冲区的 write()函数，在 reducer 里边会执行 read()</strong> 。所以如果不实现那两个函数，Reducer 取到的就是空值。</p><p>在网上搜索了一写其他资料，发现情况确实如此，可以参看[<a href="http://blog.csdn.net/yongjian_luo/article/details/9962047" title="Mapreduce不设置reduce，只执行map的输出结果" target="_blank" rel="noopener">1</a>]。</p><p>因为 Mapper 的 outkey 是 NullWritable,所有的数据都会发送到同一个节点上进行 Reduce[<a href="https://www.quora.com/Whats-the-key-value-output-of-map-function-if-I-use-context-write-NullWritable-get-new-Text-1" title="What&#39;s the &lt;key, value&gt; output of map function if I use context.write (NullWritable.get(),new Text(1))?" target="_blank" rel="noopener">2</a>]，速度非常慢，这无疑是与初衷相背的，更好的解决办法是参照[<a href="http://blog.csdn.net/yongjian_luo/article/details/9962047" title="Mapreduce不设置reduce，只执行map的输出结果" target="_blank" rel="noopener">1</a>]中的第四条，将 reduce 的数量设置为0，这样 mapper 就不再执行 Writable 的两个函数，会直接写入数据库。</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">0</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure><p><strong>总结:</strong><br>1.如果不设置 Reducer，Hadoop 还是会默认执行一个的，所以最好明确设置 Reducer 的数量为0，这样可以在 Map 阶段就执行输出。<br>2.Map 的 OutputKeyClass 为 NullWritable 的时候，所有的 Reduce 都会发送给一个结点计算，所以不要用 NullWritable 作为Map 的OutputKeyClass.</p><p><strong>参考:</strong></p><p>[1]:<a href="http://blog.csdn.net/yongjian_luo/article/details/9962047" title="Mapreduce不设置reduce，只执行map的输出结果" target="_blank" rel="noopener">Mapreduce不设置reduce，只执行map的输出结果</a><br>[2]:<a href="https://www.quora.com/Whats-the-key-value-output-of-map-function-if-I-use-context-write-NullWritable-get-new-Text-1" title="What&#39;s the &lt;key, value&gt; output of map function if I use context.write (NullWritable.get(),new Text(1))?" target="_blank" rel="noopener">What’s the &lt;key, value&gt; output of map function if I use context.write (NullWritable.get(),new Text(1))?</a></p>]]></content>
    
    <summary type="html">
    
      不设置 Reducer 的任务会有一个默认的 Reducer, 如果必要，明确设置job.setNumReduceTasks(0);
    
    </summary>
    
      <category term="HBase" scheme="http://dequn.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://dequn.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="http://dequn.github.io/tags/MapReduce/"/>
    
  </entry>
  
</feed>
